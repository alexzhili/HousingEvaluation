{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d46a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import socket\n",
    "import os\n",
    "\n",
    "spark_master = os.environ.get('SPARK_MASTER') # \"spark://spark-master:7077\" \n",
    "driver_host = socket.gethostbyname(socket.gethostname()) # setting driver host is important in k8s mode, ortherwise excutors cannot find diver host\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(spark_master)\\\n",
    "    .appName(\"catboost\") \\\n",
    "    .config(\"spark.driver.host\", driver_host) \\\n",
    "    .config(\"spark.jars.packages\", \"ai.catboost:catboost-spark_3.0_2.12:1.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "701fc5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.38.0.2-1-3.3\n"
     ]
    }
   ],
   "source": [
    "import pysparkling as pd\n",
    "\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3441cce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/spark-3.3.0-bin-hadoop3/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "ai.h2o#sparkling-water-package_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-cb39d5f4-4fa5-45c8-923a-227566f424f1;1.0\n",
      "\tconfs: [default]\n",
      "\tfound ai.h2o#sparkling-water-package_2.12;3.38.0.1-1-3.3 in central\n",
      "downloading https://repo1.maven.org/maven2/ai/h2o/sparkling-water-package_2.12/3.38.0.1-1-3.3/sparkling-water-package_2.12-3.38.0.1-1-3.3.jar ...\n",
      "\t[SUCCESSFUL ] ai.h2o#sparkling-water-package_2.12;3.38.0.1-1-3.3!sparkling-water-package_2.12.jar (58010ms)\n",
      ":: resolution report :: resolve 422ms :: artifacts dl 58012ms\n",
      "\t:: modules in use:\n",
      "\tai.h2o#sparkling-water-package_2.12;3.38.0.1-1-3.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   1   |   1   |   0   ||   1   |   1   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-cb39d5f4-4fa5-45c8-923a-227566f424f1\n",
      "\tconfs: [default]\n",
      "\t1 artifacts copied, 0 already retrieved (164856kB/161ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/01 15:48:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/01 15:48:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import socket\n",
    "import os\n",
    "\n",
    "spark_master = os.environ.get('SPARK_MASTER') # \"spark://spark-master:7077\" \n",
    "driver_host = socket.gethostbyname(socket.gethostname()) # setting driver host is important in k8s mode, ortherwise excutors cannot find diver host\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(spark_master)\\\n",
    "    .appName(\"catboost\") \\\n",
    "    .config(\"spark.driver.host\", driver_host) \\\n",
    "    .config(\"spark.jars.packages\", \"ai.h2o:sparkling-water-package_2.12:3.38.0.1-1-3.3\") \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eba277d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/01 15:51:00 WARN InternalH2OBackend: Increasing 'spark.locality.wait' to value 0 (Infinitive) as we need to ensure we run on the nodes with H2O\n",
      "22/11/01 15:51:00 WARN InternalH2OBackend: The property 'spark.scheduler.minRegisteredResourcesRatio' is not specified!\n",
      "We recommend to pass `--conf spark.scheduler.minRegisteredResourcesRatio=1`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to H2O server at http://172.27.0.3:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>12 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/GMT</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.38.0.1</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 13 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>sparkling-water-root_app-20221101154832-0008</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>4 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://172.27.0.3:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>null</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.7 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  --------------------------------------------\n",
       "H2O_cluster_uptime:         12 secs\n",
       "H2O_cluster_timezone:       Etc/GMT\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.38.0.1\n",
       "H2O_cluster_version_age:    1 month and 13 days\n",
       "H2O_cluster_name:           sparkling-water-root_app-20221101154832-0008\n",
       "H2O_cluster_total_nodes:    4\n",
       "H2O_cluster_free_memory:    4 Gb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  16\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://172.27.0.3:54321\n",
       "H2O_connection_proxy:       null\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.7 final\n",
       "--------------------------  --------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sparkling Water Context:\n",
      " * Sparkling Water Version: 3.38.0.1-1-3.3\n",
      " * H2O name: root\n",
      " * cluster size: 4\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (0,172.27.0.4,54321)\n",
      "  (1,172.27.0.5,54321)\n",
      "  (2,172.27.0.6,54321)\n",
      "  (3,172.27.0.7,54321)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://172.27.0.3:54321 (CMD + click in Mac OSX)\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from pysparkling.ml import H2OXGBoostRegressor\n",
    "from pysparkling import *\n",
    "\n",
    "hc = H2OContext.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "face800c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40280981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class H2OXGBoostRegressor in module ai.h2o.sparkling.ml.algos.regression.H2OXGBoostRegressor:\n",
      "\n",
      "class H2OXGBoostRegressor(ai.h2o.sparkling.ml.algos.H2OXGBoost.H2OXGBoost)\n",
      " |  H2OXGBoostRegressor(monotoneConstraints={}, calibrationDataFrame=None, ignoredCols=None, columnsToCategorical=[], keepBinaryModels=False, withContributions=False, dataFrameSerializer='ai.h2o.sparkling.utils.JSONDataFrameSerializer', withLeafNodeAssignments=False, namedMojoOutputColumns=True, convertInvalidNumbersToNa=False, detailedPredictionCol='detailed_prediction', validationDataFrame=None, featuresCols=[], predictionCol='prediction', convertUnknownCategoricalLevelsToNa=False, splitRatio=1.0, withStageResults=False, ntrees=50, maxDepth=6, minRows=1.0, minChildWeight=1.0, learnRate=0.3, eta=0.3, sampleRate=1.0, subsample=1.0, colSampleRate=1.0, colSampleByLevel=1.0, colSampleRatePerTree=1.0, colSampleByTree=1.0, colSampleByNode=1.0, maxAbsLeafnodePred=0.0, maxDeltaStep=0.0, scoreTreeInterval=0, seed=-1, minSplitImprovement=0.0, gamma=0.0, nthread=-1, buildTreeOneNode=False, saveMatrixDirectory=None, calibrateModel=False, calibrationMethod='AUTO', maxBins=256, maxLeaves=0, treeMethod='auto', growPolicy='depthwise', booster='gbtree', regLambda=1.0, regAlpha=0.0, quietMode=True, sampleType='uniform', normalizeType='tree', rateDrop=0.0, oneDrop=False, skipDrop=0.0, dmatrixType='auto', backend='auto', gpuId=None, interactionConstraints=None, scalePosWeight=1.0, modelId=None, nfolds=0, keepCrossValidationModels=True, keepCrossValidationPredictions=False, keepCrossValidationFoldAssignment=False, distribution='AUTO', tweediePower=1.5, labelCol='label', weightCol=None, offsetCol=None, foldCol=None, foldAssignment='AUTO', categoricalEncoding='AUTO', ignoreConstCols=True, scoreEachIteration=False, stoppingRounds=0, maxRuntimeSecs=0.0, stoppingMetric='AUTO', stoppingTolerance=0.001, gainsliftBins=-1, exportCheckpointsDir=None, aucType='AUTO')\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      H2OXGBoostRegressor\n",
      " |      ai.h2o.sparkling.ml.algos.H2OXGBoost.H2OXGBoost\n",
      " |      ai.h2o.sparkling.ml.params.H2OXGBoostParams.H2OXGBoostParams\n",
      " |      ai.h2o.sparkling.ml.params.HasMonotoneConstraints.HasMonotoneConstraints\n",
      " |      ai.h2o.sparkling.ml.params.HasCalibrationDataFrame.HasCalibrationDataFrame\n",
      " |      ai.h2o.sparkling.ml.params.HasIgnoredCols.HasIgnoredCols\n",
      " |      ai.h2o.sparkling.ml.algos.H2OTreeBasedSupervisedAlgorithm.H2OTreeBasedSupervisedAlgorithm\n",
      " |      ai.h2o.sparkling.ml.algos.H2OSupervisedAlgorithmWithFoldColumn.H2OSupervisedAlgorithmWithFoldColumn\n",
      " |      ai.h2o.sparkling.ml.algos.H2OSupervisedAlgorithm.H2OSupervisedAlgorithm\n",
      " |      ai.h2o.sparkling.ml.algos.H2OAlgorithm.H2OAlgorithm\n",
      " |      ai.h2o.sparkling.ml.algos.H2OEstimator.H2OEstimator\n",
      " |      ai.h2o.sparkling.ml.H2OStageBase.H2OStageBase\n",
      " |      pyspark.ml.util.JavaMLReadable\n",
      " |      pyspark.ml.util.MLReadable\n",
      " |      pyspark.ml.wrapper.JavaEstimator\n",
      " |      pyspark.ml.wrapper.JavaParams\n",
      " |      pyspark.ml.wrapper.JavaWrapper\n",
      " |      pyspark.ml.base.Estimator\n",
      " |      ai.h2o.sparkling.ml.params.H2OAlgorithmCommonParams.H2OAlgorithmCommonParams\n",
      " |      ai.h2o.sparkling.ml.params.H2OCommonParams.H2OCommonParams\n",
      " |      ai.h2o.sparkling.ml.params.H2OAlgorithmMOJOParams.H2OAlgorithmMOJOParams\n",
      " |      ai.h2o.sparkling.ml.params.H2OBaseMOJOParams.H2OBaseMOJOParams\n",
      " |      pyspark.ml.param.Params\n",
      " |      pyspark.ml.util.Identifiable\n",
      " |      typing.Generic\n",
      " |      pyspark.ml.util.JavaMLWritable\n",
      " |      pyspark.ml.util.MLWritable\n",
      " |      ai.h2o.sparkling.ml.algos.DistributionBasedH2OTrainFramePreparation.DistributionBasedH2OTrainFramePreparation\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, monotoneConstraints={}, calibrationDataFrame=None, ignoredCols=None, columnsToCategorical=[], keepBinaryModels=False, withContributions=False, dataFrameSerializer='ai.h2o.sparkling.utils.JSONDataFrameSerializer', withLeafNodeAssignments=False, namedMojoOutputColumns=True, convertInvalidNumbersToNa=False, detailedPredictionCol='detailed_prediction', validationDataFrame=None, featuresCols=[], predictionCol='prediction', convertUnknownCategoricalLevelsToNa=False, splitRatio=1.0, withStageResults=False, ntrees=50, maxDepth=6, minRows=1.0, minChildWeight=1.0, learnRate=0.3, eta=0.3, sampleRate=1.0, subsample=1.0, colSampleRate=1.0, colSampleByLevel=1.0, colSampleRatePerTree=1.0, colSampleByTree=1.0, colSampleByNode=1.0, maxAbsLeafnodePred=0.0, maxDeltaStep=0.0, scoreTreeInterval=0, seed=-1, minSplitImprovement=0.0, gamma=0.0, nthread=-1, buildTreeOneNode=False, saveMatrixDirectory=None, calibrateModel=False, calibrationMethod='AUTO', maxBins=256, maxLeaves=0, treeMethod='auto', growPolicy='depthwise', booster='gbtree', regLambda=1.0, regAlpha=0.0, quietMode=True, sampleType='uniform', normalizeType='tree', rateDrop=0.0, oneDrop=False, skipDrop=0.0, dmatrixType='auto', backend='auto', gpuId=None, interactionConstraints=None, scalePosWeight=1.0, modelId=None, nfolds=0, keepCrossValidationModels=True, keepCrossValidationPredictions=False, keepCrossValidationFoldAssignment=False, distribution='AUTO', tweediePower=1.5, labelCol='label', weightCol=None, offsetCol=None, foldCol=None, foldAssignment='AUTO', categoricalEncoding='AUTO', ignoreConstCols=True, scoreEachIteration=False, stoppingRounds=0, maxRuntimeSecs=0.0, stoppingMetric='AUTO', stoppingTolerance=0.001, gainsliftBins=-1, exportCheckpointsDir=None, aucType='AUTO')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __parameters__ = ()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ai.h2o.sparkling.ml.params.H2OXGBoostParams.H2OXGBoostParams:\n",
      " |  \n",
      " |  getAucType(self)\n",
      " |  \n",
      " |  getBackend(self)\n",
      " |  \n",
      " |  getBooster(self)\n",
      " |  \n",
      " |  getBuildTreeOneNode(self)\n",
      " |  \n",
      " |  getCalibrateModel(self)\n",
      " |  \n",
      " |  getCalibrationMethod(self)\n",
      " |  \n",
      " |  getCategoricalEncoding(self)\n",
      " |  \n",
      " |  getColSampleByLevel(self)\n",
      " |  \n",
      " |  getColSampleByNode(self)\n",
      " |  \n",
      " |  getColSampleByTree(self)\n",
      " |  \n",
      " |  getColSampleRate(self)\n",
      " |  \n",
      " |  getColSampleRatePerTree(self)\n",
      " |  \n",
      " |  getDistribution(self)\n",
      " |  \n",
      " |  getDmatrixType(self)\n",
      " |  \n",
      " |  getEta(self)\n",
      " |  \n",
      " |  getExportCheckpointsDir(self)\n",
      " |  \n",
      " |  getFoldAssignment(self)\n",
      " |  \n",
      " |  getFoldCol(self)\n",
      " |  \n",
      " |  getGainsliftBins(self)\n",
      " |  \n",
      " |  getGamma(self)\n",
      " |  \n",
      " |  getGpuId(self)\n",
      " |  \n",
      " |  getGrowPolicy(self)\n",
      " |  \n",
      " |  getIgnoreConstCols(self)\n",
      " |  \n",
      " |  getInteractionConstraints(self)\n",
      " |  \n",
      " |  getKeepCrossValidationFoldAssignment(self)\n",
      " |  \n",
      " |  getKeepCrossValidationModels(self)\n",
      " |  \n",
      " |  getKeepCrossValidationPredictions(self)\n",
      " |  \n",
      " |  getLabelCol(self)\n",
      " |  \n",
      " |  getLearnRate(self)\n",
      " |  \n",
      " |  getMaxAbsLeafnodePred(self)\n",
      " |  \n",
      " |  getMaxBins(self)\n",
      " |  \n",
      " |  getMaxDeltaStep(self)\n",
      " |  \n",
      " |  getMaxDepth(self)\n",
      " |  \n",
      " |  getMaxLeaves(self)\n",
      " |  \n",
      " |  getMaxRuntimeSecs(self)\n",
      " |  \n",
      " |  getMinChildWeight(self)\n",
      " |  \n",
      " |  getMinRows(self)\n",
      " |  \n",
      " |  getMinSplitImprovement(self)\n",
      " |  \n",
      " |  getModelId(self)\n",
      " |  \n",
      " |  getNfolds(self)\n",
      " |  \n",
      " |  getNormalizeType(self)\n",
      " |  \n",
      " |  getNthread(self)\n",
      " |  \n",
      " |  getNtrees(self)\n",
      " |      ##\n",
      " |      # Getters\n",
      " |      ##\n",
      " |  \n",
      " |  getOffsetCol(self)\n",
      " |  \n",
      " |  getOneDrop(self)\n",
      " |  \n",
      " |  getQuietMode(self)\n",
      " |  \n",
      " |  getRateDrop(self)\n",
      " |  \n",
      " |  getRegAlpha(self)\n",
      " |  \n",
      " |  getRegLambda(self)\n",
      " |  \n",
      " |  getSampleRate(self)\n",
      " |  \n",
      " |  getSampleType(self)\n",
      " |  \n",
      " |  getSaveMatrixDirectory(self)\n",
      " |  \n",
      " |  getScalePosWeight(self)\n",
      " |  \n",
      " |  getScoreEachIteration(self)\n",
      " |  \n",
      " |  getScoreTreeInterval(self)\n",
      " |  \n",
      " |  getSeed(self)\n",
      " |  \n",
      " |  getSkipDrop(self)\n",
      " |  \n",
      " |  getStoppingMetric(self)\n",
      " |  \n",
      " |  getStoppingRounds(self)\n",
      " |  \n",
      " |  getStoppingTolerance(self)\n",
      " |  \n",
      " |  getSubsample(self)\n",
      " |  \n",
      " |  getTreeMethod(self)\n",
      " |  \n",
      " |  getTweediePower(self)\n",
      " |  \n",
      " |  getWeightCol(self)\n",
      " |  \n",
      " |  setAucType(self, value)\n",
      " |  \n",
      " |  setBackend(self, value)\n",
      " |  \n",
      " |  setBooster(self, value)\n",
      " |  \n",
      " |  setBuildTreeOneNode(self, value)\n",
      " |  \n",
      " |  setCalibrateModel(self, value)\n",
      " |  \n",
      " |  setCalibrationMethod(self, value)\n",
      " |  \n",
      " |  setCategoricalEncoding(self, value)\n",
      " |  \n",
      " |  setColSampleByLevel(self, value)\n",
      " |  \n",
      " |  setColSampleByNode(self, value)\n",
      " |  \n",
      " |  setColSampleByTree(self, value)\n",
      " |  \n",
      " |  setColSampleRate(self, value)\n",
      " |  \n",
      " |  setColSampleRatePerTree(self, value)\n",
      " |  \n",
      " |  setDistribution(self, value)\n",
      " |  \n",
      " |  setDmatrixType(self, value)\n",
      " |  \n",
      " |  setEta(self, value)\n",
      " |  \n",
      " |  setExportCheckpointsDir(self, value)\n",
      " |  \n",
      " |  setFoldAssignment(self, value)\n",
      " |  \n",
      " |  setFoldCol(self, value)\n",
      " |  \n",
      " |  setGainsliftBins(self, value)\n",
      " |  \n",
      " |  setGamma(self, value)\n",
      " |  \n",
      " |  setGpuId(self, value)\n",
      " |  \n",
      " |  setGrowPolicy(self, value)\n",
      " |  \n",
      " |  setIgnoreConstCols(self, value)\n",
      " |  \n",
      " |  setInteractionConstraints(self, value)\n",
      " |  \n",
      " |  setKeepCrossValidationFoldAssignment(self, value)\n",
      " |  \n",
      " |  setKeepCrossValidationModels(self, value)\n",
      " |  \n",
      " |  setKeepCrossValidationPredictions(self, value)\n",
      " |  \n",
      " |  setLabelCol(self, value)\n",
      " |  \n",
      " |  setLearnRate(self, value)\n",
      " |  \n",
      " |  setMaxAbsLeafnodePred(self, value)\n",
      " |  \n",
      " |  setMaxBins(self, value)\n",
      " |  \n",
      " |  setMaxDeltaStep(self, value)\n",
      " |  \n",
      " |  setMaxDepth(self, value)\n",
      " |  \n",
      " |  setMaxLeaves(self, value)\n",
      " |  \n",
      " |  setMaxRuntimeSecs(self, value)\n",
      " |  \n",
      " |  setMinChildWeight(self, value)\n",
      " |  \n",
      " |  setMinRows(self, value)\n",
      " |  \n",
      " |  setMinSplitImprovement(self, value)\n",
      " |  \n",
      " |  setModelId(self, value)\n",
      " |  \n",
      " |  setNfolds(self, value)\n",
      " |  \n",
      " |  setNormalizeType(self, value)\n",
      " |  \n",
      " |  setNthread(self, value)\n",
      " |  \n",
      " |  setNtrees(self, value)\n",
      " |      ##\n",
      " |      # Setters\n",
      " |      ##\n",
      " |  \n",
      " |  setOffsetCol(self, value)\n",
      " |  \n",
      " |  setOneDrop(self, value)\n",
      " |  \n",
      " |  setQuietMode(self, value)\n",
      " |  \n",
      " |  setRateDrop(self, value)\n",
      " |  \n",
      " |  setRegAlpha(self, value)\n",
      " |  \n",
      " |  setRegLambda(self, value)\n",
      " |  \n",
      " |  setSampleRate(self, value)\n",
      " |  \n",
      " |  setSampleType(self, value)\n",
      " |  \n",
      " |  setSaveMatrixDirectory(self, value)\n",
      " |  \n",
      " |  setScalePosWeight(self, value)\n",
      " |  \n",
      " |  setScoreEachIteration(self, value)\n",
      " |  \n",
      " |  setScoreTreeInterval(self, value)\n",
      " |  \n",
      " |  setSeed(self, value)\n",
      " |  \n",
      " |  setSkipDrop(self, value)\n",
      " |  \n",
      " |  setStoppingMetric(self, value)\n",
      " |  \n",
      " |  setStoppingRounds(self, value)\n",
      " |  \n",
      " |  setStoppingTolerance(self, value)\n",
      " |  \n",
      " |  setSubsample(self, value)\n",
      " |  \n",
      " |  setTreeMethod(self, value)\n",
      " |  \n",
      " |  setTweediePower(self, value)\n",
      " |  \n",
      " |  setWeightCol(self, value)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from ai.h2o.sparkling.ml.params.H2OXGBoostParams.H2OXGBoostParams:\n",
      " |  \n",
      " |  aucType = Param(parent='undefined', name='aucType', doc='Set default m...\n",
      " |  \n",
      " |  backend = Param(parent='undefined', name='backend', doc='B... By defau...\n",
      " |  \n",
      " |  booster = Param(parent='undefined', name='booster', doc='Booster type'...\n",
      " |  \n",
      " |  buildTreeOneNode = Param(parent='undefined', name='buildTreeOneNode......\n",
      " |  \n",
      " |  calibrateModel = Param(parent='undefined', name='calibrateModel',...mo...\n",
      " |  \n",
      " |  calibrationMethod = Param(parent='undefined', name='calibrationMethod'...\n",
      " |  \n",
      " |  categoricalEncoding = Param(parent='undefined', name='categoricalEncod...\n",
      " |  \n",
      " |  colSampleByLevel = Param(parent='undefined', name='colSampleByLevel......\n",
      " |  \n",
      " |  colSampleByNode = Param(parent='undefined', name='colSampleByNode'...u...\n",
      " |  \n",
      " |  colSampleByTree = Param(parent='undefined', name='colSampleByTree'...)...\n",
      " |  \n",
      " |  colSampleRate = Param(parent='undefined', name='colSampleRate', ...e_b...\n",
      " |  \n",
      " |  colSampleRatePerTree = Param(parent='undefined', name='colSampleRatePe...\n",
      " |  \n",
      " |  distribution = Param(parent='undefined', name='distribution', doc='Dis...\n",
      " |  \n",
      " |  dmatrixType = Param(parent='undefined', name='dmatrixType', do...rix. ...\n",
      " |  \n",
      " |  eta = Param(parent='undefined', name='eta', doc='(same as learn_rate) ...\n",
      " |  \n",
      " |  exportCheckpointsDir = Param(parent='undefined', name='exportCheckpoin...\n",
      " |  \n",
      " |  foldAssignment = Param(parent='undefined', name='foldAssignment',...re...\n",
      " |  \n",
      " |  foldCol = Param(parent='undefined', name='foldCol', doc='C...lidation ...\n",
      " |  \n",
      " |  gainsliftBins = Param(parent='undefined', name='gainsliftBins', ...led...\n",
      " |  \n",
      " |  gamma = Param(parent='undefined', name='gamma', doc='(sa...n squared e...\n",
      " |  \n",
      " |  gpuId = Param(parent='undefined', name='gpuId', doc='Which GPU(s) to u...\n",
      " |  \n",
      " |  growPolicy = Param(parent='undefined', name='growPolicy', doc...epthwi...\n",
      " |  \n",
      " |  ignoreConstCols = Param(parent='undefined', name='ignoreConstCols', do...\n",
      " |  \n",
      " |  interactionConstraints = Param(parent='undefined', name='interactionCo...\n",
      " |  \n",
      " |  keepCrossValidationFoldAssignment = Param(parent='undefined', name='ke...\n",
      " |  \n",
      " |  keepCrossValidationModels = Param(parent='undefined', name='keepCrossV...\n",
      " |  \n",
      " |  keepCrossValidationPredictions = Param(parent='undefined', name='keepC...\n",
      " |  \n",
      " |  labelCol = Param(parent='undefined', name='labelCol', doc='Response va...\n",
      " |  \n",
      " |  learnRate = Param(parent='undefined', name='learnRate', doc='(same as ...\n",
      " |  \n",
      " |  maxAbsLeafnodePred = Param(parent='undefined', name='maxAbsLeafnodePr....\n",
      " |  \n",
      " |  maxBins = Param(parent='undefined', name='maxBins', doc='For tree_meth...\n",
      " |  \n",
      " |  maxDeltaStep = Param(parent='undefined', name='maxDeltaStep', d...axim...\n",
      " |  \n",
      " |  maxDepth = Param(parent='undefined', name='maxDepth', doc='Maximum tre...\n",
      " |  \n",
      " |  maxLeaves = Param(parent='undefined', name='maxLeaves', doc=...tree_me...\n",
      " |  \n",
      " |  maxRuntimeSecs = Param(parent='undefined', name='maxRuntimeSecs',...n ...\n",
      " |  \n",
      " |  minChildWeight = Param(parent='undefined', name='minChildWeight',...we...\n",
      " |  \n",
      " |  minRows = Param(parent='undefined', name='minRows', doc='(...west allo...\n",
      " |  \n",
      " |  minSplitImprovement = Param(parent='undefined', name='minSplitImprovem...\n",
      " |  \n",
      " |  modelId = Param(parent='undefined', name='modelId', doc='D...or this m...\n",
      " |  \n",
      " |  nfolds = Param(parent='undefined', name='nfolds', doc='Nu...K-fold cro...\n",
      " |  \n",
      " |  normalizeType = Param(parent='undefined', name='normalizeType', doc='F...\n",
      " |  \n",
      " |  nthread = Param(parent='undefined', name='nthread', doc='N...reads par...\n",
      " |  \n",
      " |  ntrees = Param(parent='undefined', name='ntrees', doc='(same as n_esti...\n",
      " |  \n",
      " |  offsetCol = Param(parent='undefined', name='offsetCol', doc=...n of co...\n",
      " |  \n",
      " |  oneDrop = Param(parent='undefined', name='oneDrop', doc='For booster=d...\n",
      " |  \n",
      " |  quietMode = Param(parent='undefined', name='quietMode', doc='Enable qu...\n",
      " |  \n",
      " |  rateDrop = Param(parent='undefined', name='rateDrop', doc='For booster...\n",
      " |  \n",
      " |  regAlpha = Param(parent='undefined', name='regAlpha', doc='L1 regulari...\n",
      " |  \n",
      " |  regLambda = Param(parent='undefined', name='regLambda', doc='L2 regula...\n",
      " |  \n",
      " |  sampleRate = Param(parent='undefined', name='sampleRate', doc...ple) R...\n",
      " |  \n",
      " |  sampleType = Param(parent='undefined', name='sampleType', doc='For boo...\n",
      " |  \n",
      " |  saveMatrixDirectory = Param(parent='undefined', name='saveMatrixDirect...\n",
      " |  \n",
      " |  scalePosWeight = Param(parent='undefined', name='scalePosWeight',...nt...\n",
      " |  \n",
      " |  scoreEachIteration = Param(parent='undefined', name='scoreEachIterati....\n",
      " |  \n",
      " |  scoreTreeInterval = Param(parent='undefined', name='scoreTreeInterva.....\n",
      " |  \n",
      " |  seed = Param(parent='undefined', name='seed', doc='Seed... pseudo rand...\n",
      " |  \n",
      " |  skipDrop = Param(parent='undefined', name='skipDrop', doc='For booster...\n",
      " |  \n",
      " |  stoppingMetric = Param(parent='undefined', name='stoppingMetric',... b...\n",
      " |  \n",
      " |  stoppingRounds = Param(parent='undefined', name='stoppingRounds',...:=...\n",
      " |  \n",
      " |  stoppingTolerance = Param(parent='undefined', name='stoppingToleranc.....\n",
      " |  \n",
      " |  subsample = Param(parent='undefined', name='subsample', doc=...ate) Ro...\n",
      " |  \n",
      " |  treeMethod = Param(parent='undefined', name='treeMethod', doc='Tree me...\n",
      " |  \n",
      " |  tweediePower = Param(parent='undefined', name='tweediePower', d...or T...\n",
      " |  \n",
      " |  weightCol = Param(parent='undefined', name='weightCol', doc=...e predi...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ai.h2o.sparkling.ml.params.HasMonotoneConstraints.HasMonotoneConstraints:\n",
      " |  \n",
      " |  getMonotoneConstraints(self)\n",
      " |  \n",
      " |  setMonotoneConstraints(self, value)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from ai.h2o.sparkling.ml.params.HasMonotoneConstraints.HasMonotoneConstraints:\n",
      " |  \n",
      " |  monotoneConstraints = Param(parent='undefined', name='monotoneConstrai...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ai.h2o.sparkling.ml.params.HasCalibrationDataFrame.HasCalibrationDataFrame:\n",
      " |  \n",
      " |  getCalibrationDataFrame(self)\n",
      " |  \n",
      " |  setCalibrationDataFrame(self, value)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from ai.h2o.sparkling.ml.params.HasCalibrationDataFrame.HasCalibrationDataFrame:\n",
      " |  \n",
      " |  calibrationDataFrame = Param(parent='undefined', name='calibrationData...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ai.h2o.sparkling.ml.params.HasIgnoredCols.HasIgnoredCols:\n",
      " |  \n",
      " |  getIgnoredCols(self)\n",
      " |  \n",
      " |  setIgnoredCols(self, value)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from ai.h2o.sparkling.ml.params.HasIgnoredCols.HasIgnoredCols:\n",
      " |  \n",
      " |  ignoredCols = Param(parent='undefined', name='ignoredCols', doc='Names...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ai.h2o.sparkling.ml.algos.H2OEstimator.H2OEstimator:\n",
      " |  \n",
      " |  getBinaryModel(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pyspark.ml.util.JavaMLReadable:\n",
      " |  \n",
      " |  read() -> pyspark.ml.util.JavaMLReader[~RL] from abc.ABCMeta\n",
      " |      Returns an MLReader instance for this class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pyspark.ml.util.JavaMLReadable:\n",
      " |  \n",
      " |  __orig_bases__ = (pyspark.ml.util.MLReadable[~RL],)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pyspark.ml.util.MLReadable:\n",
      " |  \n",
      " |  load(path: str) -> ~RL from abc.ABCMeta\n",
      " |      Reads an ML instance from the input path, a shortcut of `read().load(path)`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pyspark.ml.util.MLReadable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pyspark.ml.wrapper.JavaParams:\n",
      " |  \n",
      " |  clear(self, param: pyspark.ml.param.Param) -> None\n",
      " |      Clears a param from the param map if it has been explicitly set.\n",
      " |  \n",
      " |  copy(self: 'JP', extra: Optional[ForwardRef('ParamMap')] = None) -> 'JP'\n",
      " |      Creates a copy of this instance with the same uid and some\n",
      " |      extra params. This implementation first calls Params.copy and\n",
      " |      then make a copy of the companion Java pipeline component with\n",
      " |      extra params. So both the Python wrapper and the Java pipeline\n",
      " |      component get copied.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      extra : dict, optional\n",
      " |          Extra parameters to copy to the new instance\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :py:class:`JavaParams`\n",
      " |          Copy of this instance\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pyspark.ml.wrapper.JavaWrapper:\n",
      " |  \n",
      " |  __del__(self) -> None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pyspark.ml.base.Estimator:\n",
      " |  \n",
      " |  fit(self, dataset: pyspark.sql.dataframe.DataFrame, params: Union[ForwardRef('ParamMap'), List[ForwardRef('ParamMap')], Tuple[ForwardRef('ParamMap')], NoneType] = None) -> Union[~M, List[~M]]\n",
      " |      Fits a model to the input dataset with optional parameters.\n",
      " |      \n",
      " |      .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset : :py:class:`pyspark.sql.DataFrame`\n",
      " |          input dataset.\n",
      " |      params : dict or list or tuple, optional\n",
      " |          an optional param map that overrides embedded params. If a list/tuple of\n",
      " |          param maps is given, this calls fit on each param map and returns a list of\n",
      " |          models.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :py:class:`Transformer` or a list of :py:class:`Transformer`\n",
      " |          fitted model(s)\n",
      " |  \n",
      " |  fitMultiple(self, dataset: pyspark.sql.dataframe.DataFrame, paramMaps: Sequence[ForwardRef('ParamMap')]) -> Iterator[Tuple[int, ~M]]\n",
      " |      Fits a model to the input dataset for each param map in `paramMaps`.\n",
      " |      \n",
      " |      .. versionadded:: 2.3.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset : :py:class:`pyspark.sql.DataFrame`\n",
      " |          input dataset.\n",
      " |      paramMaps : :py:class:`collections.abc.Sequence`\n",
      " |          A Sequence of param maps.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :py:class:`_FitMultipleIterator`\n",
      " |          A thread safe iterable which contains one model for each param map. Each\n",
      " |          call to `next(modelIterator)` will return `(index, model)` where model was fit\n",
      " |          using `paramMaps[index]`. `index` values may not be sequential.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ai.h2o.sparkling.ml.params.H2OAlgorithmCommonParams.H2OAlgorithmCommonParams:\n",
      " |  \n",
      " |  setDetailedPredictionCol(self, value)\n",
      " |  \n",
      " |  setFeaturesCols(self, value)\n",
      " |  \n",
      " |  setNamedMojoOutputColumns(self, value)\n",
      " |  \n",
      " |  setPredictionCol(self, value)\n",
      " |      # Setters for parameters which are defined on MOJO as well\n",
      " |  \n",
      " |  setWithContributions(self, value)\n",
      " |  \n",
      " |  setWithLeafNodeAssignments(self, value)\n",
      " |  \n",
      " |  setWithStageResults(self, value)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ai.h2o.sparkling.ml.params.H2OCommonParams.H2OCommonParams:\n",
      " |  \n",
      " |  getColumnsToCategorical(self)\n",
      " |  \n",
      " |  getKeepBinaryModels(self)\n",
      " |  \n",
      " |  getSplitRatio(self)\n",
      " |  \n",
      " |  getValidationDataFrame(self)\n",
      " |      ##\n",
      " |      # Getters\n",
      " |      ##\n",
      " |  \n",
      " |  setColumnsToCategorical(self, value, *args)\n",
      " |  \n",
      " |  setConvertInvalidNumbersToNa(self, value)\n",
      " |  \n",
      " |  setConvertUnknownCategoricalLevelsToNa(self, value)\n",
      " |  \n",
      " |  setKeepBinaryModels(self, value)\n",
      " |  \n",
      " |  setSplitRatio(self, value)\n",
      " |  \n",
      " |  setValidationDataFrame(self, value)\n",
      " |      ##\n",
      " |      # Setters\n",
      " |      ##\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from ai.h2o.sparkling.ml.params.H2OCommonParams.H2OCommonParams:\n",
      " |  \n",
      " |  columnsToCategorical = Param(parent='undefined', name='columnsToCatego...\n",
      " |  \n",
      " |  keepBinaryModels = Param(parent='undefined', name='keepBinaryModels......\n",
      " |  \n",
      " |  splitRatio = Param(parent='undefined', name='splitRatio', doc...or exa...\n",
      " |  \n",
      " |  validationDataFrame = Param(parent='undefined', name='validationDataFr...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ai.h2o.sparkling.ml.params.H2OAlgorithmMOJOParams.H2OAlgorithmMOJOParams:\n",
      " |  \n",
      " |  getDetailedPredictionCol(self)\n",
      " |  \n",
      " |  getFeaturesCols(self)\n",
      " |  \n",
      " |  getNamedMojoOutputColumns(self)\n",
      " |  \n",
      " |  getPredictionCol(self)\n",
      " |      ##\n",
      " |      # Getters\n",
      " |      ##\n",
      " |  \n",
      " |  getWithContributions(self)\n",
      " |  \n",
      " |  getWithLeafNodeAssignments(self)\n",
      " |  \n",
      " |  getWithStageResults(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from ai.h2o.sparkling.ml.params.H2OAlgorithmMOJOParams.H2OAlgorithmMOJOParams:\n",
      " |  \n",
      " |  detailedPredictionCol = Param(parent='undefined', name='detailedPredic...\n",
      " |  \n",
      " |  featuresCols = Param(parent='undefined', name='featuresCols', doc='Nam...\n",
      " |  \n",
      " |  namedMojoOutputColumns = Param(parent='undefined', name='namedMojoOutp...\n",
      " |  \n",
      " |  predictionCol = Param(parent='undefined', name='predictionCol', doc='P...\n",
      " |  \n",
      " |  withContributions = Param(parent='undefined', name='withContribution.....\n",
      " |  \n",
      " |  withLeafNodeAssignments = Param(parent='undefined', name='withLeafNode...\n",
      " |  \n",
      " |  withStageResults = Param(parent='undefined', name='withStageResults......\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ai.h2o.sparkling.ml.params.H2OBaseMOJOParams.H2OBaseMOJOParams:\n",
      " |  \n",
      " |  getConvertInvalidNumbersToNa(self)\n",
      " |  \n",
      " |  getConvertUnknownCategoricalLevelsToNa(self)\n",
      " |      ##\n",
      " |      # Getters\n",
      " |      ##\n",
      " |  \n",
      " |  getDataFrameSerializer(self)\n",
      " |  \n",
      " |  setDataFrameSerializer(self, value)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from ai.h2o.sparkling.ml.params.H2OBaseMOJOParams.H2OBaseMOJOParams:\n",
      " |  \n",
      " |  convertInvalidNumbersToNa = Param(parent='undefined', name='convertInv...\n",
      " |  \n",
      " |  convertUnknownCategoricalLevelsToNa = Param(parent='undefined', name='...\n",
      " |  \n",
      " |  dataFrameSerializer = Param(parent='undefined', name='dataFrameSeriali...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pyspark.ml.param.Params:\n",
      " |  \n",
      " |  explainParam(self, param: Union[str, pyspark.ml.param.Param]) -> str\n",
      " |      Explains a single param and returns its name, doc, and optional\n",
      " |      default value and user-supplied value in a string.\n",
      " |  \n",
      " |  explainParams(self) -> str\n",
      " |      Returns the documentation of all params with their optionally\n",
      " |      default values and user-supplied values.\n",
      " |  \n",
      " |  extractParamMap(self, extra: Optional[ForwardRef('ParamMap')] = None) -> 'ParamMap'\n",
      " |      Extracts the embedded default param values and user-supplied\n",
      " |      values, and then merges them with extra values from input into\n",
      " |      a flat param map, where the latter value is used if there exist\n",
      " |      conflicts, i.e., with ordering: default param values <\n",
      " |      user-supplied values < extra.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      extra : dict, optional\n",
      " |          extra param values\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict\n",
      " |          merged param map\n",
      " |  \n",
      " |  getOrDefault(self, param: Union[str, pyspark.ml.param.Param[~T]]) -> Union[Any, ~T]\n",
      " |      Gets the value of a param in the user-supplied param map or its\n",
      " |      default value. Raises an error if neither is set.\n",
      " |  \n",
      " |  getParam(self, paramName: str) -> pyspark.ml.param.Param\n",
      " |      Gets a param by its name.\n",
      " |  \n",
      " |  hasDefault(self, param: Union[str, pyspark.ml.param.Param[Any]]) -> bool\n",
      " |      Checks whether a param has a default value.\n",
      " |  \n",
      " |  hasParam(self, paramName: str) -> bool\n",
      " |      Tests whether this instance contains a param with a given\n",
      " |      (string) name.\n",
      " |  \n",
      " |  isDefined(self, param: Union[str, pyspark.ml.param.Param[Any]]) -> bool\n",
      " |      Checks whether a param is explicitly set by user or has\n",
      " |      a default value.\n",
      " |  \n",
      " |  isSet(self, param: Union[str, pyspark.ml.param.Param[Any]]) -> bool\n",
      " |      Checks whether a param is explicitly set by user.\n",
      " |  \n",
      " |  set(self, param: pyspark.ml.param.Param, value: Any) -> None\n",
      " |      Sets a parameter in the embedded param map.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pyspark.ml.param.Params:\n",
      " |  \n",
      " |  params\n",
      " |      Returns all params ordered by name. The default implementation\n",
      " |      uses :py:func:`dir` to get all attributes of type\n",
      " |      :py:class:`Param`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pyspark.ml.util.Identifiable:\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from abc.ABCMeta\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pyspark.ml.util.JavaMLWritable:\n",
      " |  \n",
      " |  write(self) -> pyspark.ml.util.JavaMLWriter\n",
      " |      Returns an MLWriter instance for this ML instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pyspark.ml.util.MLWritable:\n",
      " |  \n",
      " |  save(self, path: str) -> None\n",
      " |      Save this ML instance to the given path, a shortcut of 'write().save(path)'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(H2OXGBoostRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72253054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7394d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af31d39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://mmlspark.azureedge.net/maven added as a remote repository with the name: repo-1\n",
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.microsoft.azure#synapseml_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f28fea49-eb9a-4093-8359-d7855837196e;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/spark-3.3.0-bin-hadoop3/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound com.microsoft.azure#synapseml_2.12;0.10.1 in central\n",
      "\tfound com.microsoft.azure#synapseml-core_2.12;0.10.1 in central\n",
      "\tfound org.scalactic#scalactic_2.12;3.0.5 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.4 in central\n",
      "\tfound io.spray#spray-json_2.12;1.3.5 in central\n",
      "\tfound com.jcraft#jsch;0.1.54 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.6 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.10 in central\n",
      "\tfound commons-logging#commons-logging;1.2 in central\n",
      "\tfound commons-codec#commons-codec;1.10 in central\n",
      "\tfound org.apache.httpcomponents#httpmime;4.5.6 in central\n",
      "\tfound com.linkedin.isolation-forest#isolation-forest_3.2.0_2.12;2.0.8 in central\n",
      "\tfound com.chuusai#shapeless_2.12;2.3.2 in central\n",
      "\tfound org.typelevel#macro-compat_2.12;1.1.1 in central\n",
      "\tfound org.apache.spark#spark-avro_2.12;3.2.0 in central\n",
      "\tfound org.tukaani#xz;1.8 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.testng#testng;6.8.8 in central\n",
      "\tfound org.beanshell#bsh;2.0b4 in central\n",
      "\tfound com.beust#jcommander;1.27 in central\n",
      "\tfound com.microsoft.azure#synapseml-deep-learning_2.12;0.10.1 in central\n",
      "\tfound com.microsoft.azure#synapseml-opencv_2.12;0.10.1 in central\n",
      "\tfound org.openpnp#opencv;3.2.0-1 in central\n",
      "\tfound com.microsoft.cntk#cntk;2.4 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime_gpu;1.8.1 in central\n",
      "\tfound com.microsoft.azure#synapseml-cognitive_2.12;0.10.1 in central\n",
      "\tfound com.microsoft.cognitiveservices.speech#client-jar-sdk;1.14.0 in central\n",
      "\tfound com.azure#azure-storage-blob;12.14.4 in central\n",
      "\tfound com.azure#azure-core;1.25.0 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.13.1 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.13.1 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.13.1 in central\n",
      "\tfound com.fasterxml.jackson.datatype#jackson-datatype-jsr310;2.13.1 in central\n",
      "\tfound com.fasterxml.jackson.dataformat#jackson-dataformat-xml;2.13.1 in central\n",
      "\tfound org.codehaus.woodstox#stax2-api;4.2.1 in central\n",
      "\tfound com.fasterxml.woodstox#woodstox-core;6.2.7 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.32 in central\n",
      "\tfound io.projectreactor#reactor-core;3.4.13 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound io.netty#netty-tcnative-boringssl-static;2.0.46.Final in central\n",
      "\tfound io.netty#netty-tcnative-classes;2.0.46.Final in central\n",
      "\tfound com.azure#azure-core-http-netty;1.11.7 in central\n",
      "\tfound io.netty#netty-handler;4.1.72.Final in central\n",
      "\tfound io.netty#netty-common;4.1.72.Final in central\n",
      "\tfound io.netty#netty-resolver;4.1.72.Final in central\n",
      "\tfound io.netty#netty-buffer;4.1.72.Final in central\n",
      "\tfound io.netty#netty-transport;4.1.72.Final in central\n",
      "\tfound io.netty#netty-codec;4.1.72.Final in central\n",
      "\tfound io.netty#netty-handler-proxy;4.1.72.Final in central\n",
      "\tfound io.netty#netty-codec-socks;4.1.72.Final in central\n",
      "\tfound io.netty#netty-codec-http;4.1.72.Final in central\n",
      "\tfound io.netty#netty-codec-http2;4.1.72.Final in central\n",
      "\tfound io.netty#netty-transport-native-unix-common;4.1.72.Final in central\n",
      "\tfound io.netty#netty-transport-native-epoll;4.1.72.Final in central\n",
      "\tfound io.netty#netty-transport-classes-epoll;4.1.72.Final in central\n",
      "\tfound io.netty#netty-transport-native-kqueue;4.1.72.Final in central\n",
      "\tfound io.netty#netty-transport-classes-kqueue;4.1.72.Final in central\n",
      "\tfound io.projectreactor.netty#reactor-netty-http;1.0.14 in central\n",
      "\tfound io.netty#netty-resolver-dns;4.1.72.Final in central\n",
      "\tfound io.netty#netty-codec-dns;4.1.72.Final in central\n",
      "\tfound io.netty#netty-resolver-dns-native-macos;4.1.72.Final in central\n",
      "\tfound io.netty#netty-resolver-dns-classes-macos;4.1.72.Final in central\n",
      "\tfound io.projectreactor.netty#reactor-netty-core;1.0.14 in central\n",
      "\tfound com.azure#azure-storage-common;12.14.3 in central\n",
      "\tfound com.azure#azure-storage-internal-avro;12.1.4 in central\n",
      "\tfound com.azure#azure-ai-textanalytics;5.1.6 in central\n",
      "\tfound com.microsoft.azure#synapseml-vw_2.12;0.10.1 in central\n",
      "\tfound com.github.vowpalwabbit#vw-jni;8.9.1 in central\n",
      "\tfound com.microsoft.azure#synapseml-lightgbm_2.12;0.10.1 in central\n",
      "\tfound com.microsoft.ml.lightgbm#lightgbmlib;3.2.110 in central\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/azure/synapseml_2.12/0.10.1/synapseml_2.12-0.10.1.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.azure#synapseml_2.12;0.10.1!synapseml_2.12.jar (24ms)\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/azure/synapseml-core_2.12/0.10.1/synapseml-core_2.12-0.10.1.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.azure#synapseml-core_2.12;0.10.1!synapseml-core_2.12.jar (1326ms)\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/azure/synapseml-deep-learning_2.12/0.10.1/synapseml-deep-learning_2.12-0.10.1.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.azure#synapseml-deep-learning_2.12;0.10.1!synapseml-deep-learning_2.12.jar (88ms)\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/azure/synapseml-cognitive_2.12/0.10.1/synapseml-cognitive_2.12-0.10.1.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.azure#synapseml-cognitive_2.12;0.10.1!synapseml-cognitive_2.12.jar (1124ms)\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/azure/synapseml-vw_2.12/0.10.1/synapseml-vw_2.12-0.10.1.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.azure#synapseml-vw_2.12;0.10.1!synapseml-vw_2.12.jar (208ms)\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/azure/synapseml-lightgbm_2.12/0.10.1/synapseml-lightgbm_2.12-0.10.1.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.azure#synapseml-lightgbm_2.12;0.10.1!synapseml-lightgbm_2.12.jar (204ms)\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/azure/synapseml-opencv_2.12/0.10.1/synapseml-opencv_2.12-0.10.1.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.azure#synapseml-opencv_2.12;0.10.1!synapseml-opencv_2.12.jar (124ms)\n",
      "downloading https://repo1.maven.org/maven2/org/scalactic/scalactic_2.12/3.0.5/scalactic_2.12-3.0.5.jar ...\n",
      "\t[SUCCESSFUL ] org.scalactic#scalactic_2.12;3.0.5!scalactic_2.12.jar(bundle) (247ms)\n",
      "downloading https://repo1.maven.org/maven2/io/spray/spray-json_2.12/1.3.5/spray-json_2.12-1.3.5.jar ...\n",
      "\t[SUCCESSFUL ] io.spray#spray-json_2.12;1.3.5!spray-json_2.12.jar (111ms)\n",
      "downloading https://repo1.maven.org/maven2/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar ...\n",
      "\t[SUCCESSFUL ] com.jcraft#jsch;0.1.54!jsch.jar (124ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpclient/4.5.6/httpclient-4.5.6.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.httpcomponents#httpclient;4.5.6!httpclient.jar (230ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpmime/4.5.6/httpmime-4.5.6.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.httpcomponents#httpmime;4.5.6!httpmime.jar (29ms)\n",
      "downloading https://repo1.maven.org/maven2/com/linkedin/isolation-forest/isolation-forest_3.2.0_2.12/2.0.8/isolation-forest_3.2.0_2.12-2.0.8.jar ...\n",
      "\t[SUCCESSFUL ] com.linkedin.isolation-forest#isolation-forest_3.2.0_2.12;2.0.8!isolation-forest_3.2.0_2.12.jar (132ms)\n",
      "downloading https://repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.12.4/scala-reflect-2.12.4.jar ...\n",
      "\t[SUCCESSFUL ] org.scala-lang#scala-reflect;2.12.4!scala-reflect.jar (1094ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpcore/4.4.10/httpcore-4.4.10.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.httpcomponents#httpcore;4.4.10!httpcore.jar (112ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.2/commons-logging-1.2.jar ...\n",
      "\t[SUCCESSFUL ] commons-logging#commons-logging;1.2!commons-logging.jar (43ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-codec/commons-codec/1.10/commons-codec-1.10.jar ...\n",
      "\t[SUCCESSFUL ] commons-codec#commons-codec;1.10!commons-codec.jar (97ms)\n",
      "downloading https://repo1.maven.org/maven2/com/chuusai/shapeless_2.12/2.3.2/shapeless_2.12-2.3.2.jar ...\n",
      "\t[SUCCESSFUL ] com.chuusai#shapeless_2.12;2.3.2!shapeless_2.12.jar(bundle) (810ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-avro_2.12/3.2.0/spark-avro_2.12-3.2.0.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.spark#spark-avro_2.12;3.2.0!spark-avro_2.12.jar (90ms)\n",
      "downloading https://repo1.maven.org/maven2/org/testng/testng/6.8.8/testng-6.8.8.jar ...\n",
      "\t[SUCCESSFUL ] org.testng#testng;6.8.8!testng.jar (297ms)\n",
      "downloading https://repo1.maven.org/maven2/org/typelevel/macro-compat_2.12/1.1.1/macro-compat_2.12-1.1.1.jar ...\n",
      "\t[SUCCESSFUL ] org.typelevel#macro-compat_2.12;1.1.1!macro-compat_2.12.jar (23ms)\n",
      "downloading https://repo1.maven.org/maven2/org/tukaani/xz/1.8/xz-1.8.jar ...\n",
      "\t[SUCCESSFUL ] org.tukaani#xz;1.8!xz.jar (137ms)\n",
      "downloading https://repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar ...\n",
      "\t[SUCCESSFUL ] org.spark-project.spark#unused;1.0.0!unused.jar (26ms)\n",
      "downloading https://repo1.maven.org/maven2/org/beanshell/bsh/2.0b4/bsh-2.0b4.jar ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t[SUCCESSFUL ] org.beanshell#bsh;2.0b4!bsh.jar (107ms)\n",
      "downloading https://repo1.maven.org/maven2/com/beust/jcommander/1.27/jcommander-1.27.jar ...\n",
      "\t[SUCCESSFUL ] com.beust#jcommander;1.27!jcommander.jar (45ms)\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/cntk/cntk/2.4/cntk-2.4.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.cntk#cntk;2.4!cntk.jar (59455ms)\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/onnxruntime/onnxruntime_gpu/1.8.1/onnxruntime_gpu-1.8.1.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.onnxruntime#onnxruntime_gpu;1.8.1!onnxruntime_gpu.jar (35920ms)\n",
      "downloading https://repo1.maven.org/maven2/org/openpnp/opencv/3.2.0-1/opencv-3.2.0-1.jar ...\n",
      "\t[SUCCESSFUL ] org.openpnp#opencv;3.2.0-1!opencv.jar(bundle) (20637ms)\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/cognitiveservices/speech/client-jar-sdk/1.14.0/client-jar-sdk-1.14.0.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.cognitiveservices.speech#client-jar-sdk;1.14.0!client-jar-sdk.jar (3605ms)\n",
      "downloading https://repo1.maven.org/maven2/com/azure/azure-storage-blob/12.14.4/azure-storage-blob-12.14.4.jar ...\n",
      "\t[SUCCESSFUL ] com.azure#azure-storage-blob;12.14.4!azure-storage-blob.jar (257ms)\n",
      "downloading https://repo1.maven.org/maven2/com/azure/azure-ai-textanalytics/5.1.6/azure-ai-textanalytics-5.1.6.jar ...\n",
      "\t[SUCCESSFUL ] com.azure#azure-ai-textanalytics;5.1.6!azure-ai-textanalytics.jar (111ms)\n",
      "downloading https://repo1.maven.org/maven2/com/azure/azure-core/1.25.0/azure-core-1.25.0.jar ...\n",
      "\t[SUCCESSFUL ] com.azure#azure-core;1.25.0!azure-core.jar (181ms)\n",
      "downloading https://repo1.maven.org/maven2/com/azure/azure-core-http-netty/1.11.7/azure-core-http-netty-1.11.7.jar ...\n",
      "\t[SUCCESSFUL ] com.azure#azure-core-http-netty;1.11.7!azure-core-http-netty.jar (34ms)\n",
      "downloading https://repo1.maven.org/maven2/com/azure/azure-storage-common/12.14.3/azure-storage-common-12.14.3.jar ...\n",
      "\t[SUCCESSFUL ] com.azure#azure-storage-common;12.14.3!azure-storage-common.jar (54ms)\n",
      "downloading https://repo1.maven.org/maven2/com/azure/azure-storage-internal-avro/12.1.4/azure-storage-internal-avro-12.1.4.jar ...\n",
      "\t[SUCCESSFUL ] com.azure#azure-storage-internal-avro;12.1.4!azure-storage-internal-avro.jar (72ms)\n",
      "downloading https://repo1.maven.org/maven2/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.13.1/jackson-datatype-jsr310-2.13.1.jar ...\n",
      "\t[SUCCESSFUL ] com.fasterxml.jackson.datatype#jackson-datatype-jsr310;2.13.1!jackson-datatype-jsr310.jar(bundle) (67ms)\n",
      "downloading https://repo1.maven.org/maven2/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.13.1/jackson-dataformat-xml-2.13.1.jar ...\n",
      "\t[SUCCESSFUL ] com.fasterxml.jackson.dataformat#jackson-dataformat-xml;2.13.1!jackson-dataformat-xml.jar(bundle) (54ms)\n",
      "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.32/slf4j-api-1.7.32.jar ...\n",
      "\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.32!slf4j-api.jar (32ms)\n",
      "downloading https://repo1.maven.org/maven2/io/projectreactor/reactor-core/3.4.13/reactor-core-3.4.13.jar ...\n",
      "\t[SUCCESSFUL ] io.projectreactor#reactor-core;3.4.13!reactor-core.jar (510ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-tcnative-boringssl-static/2.0.46.Final/netty-tcnative-boringssl-static-2.0.46.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-tcnative-boringssl-static;2.0.46.Final!netty-tcnative-boringssl-static.jar (1490ms)\n",
      "downloading https://repo1.maven.org/maven2/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar ...\n",
      "\t[SUCCESSFUL ] org.codehaus.woodstox#stax2-api;4.2.1!stax2-api.jar(bundle) (66ms)\n",
      "downloading https://repo1.maven.org/maven2/com/fasterxml/woodstox/woodstox-core/6.2.7/woodstox-core-6.2.7.jar ...\n",
      "\t[SUCCESSFUL ] com.fasterxml.woodstox#woodstox-core;6.2.7!woodstox-core.jar(bundle) (480ms)\n",
      "downloading https://repo1.maven.org/maven2/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar ...\n",
      "\t[SUCCESSFUL ] org.reactivestreams#reactive-streams;1.0.3!reactive-streams.jar (22ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-tcnative-classes/2.0.46.Final/netty-tcnative-classes-2.0.46.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-tcnative-classes;2.0.46.Final!netty-tcnative-classes.jar (30ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-handler/4.1.72.Final/netty-handler-4.1.72.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-handler;4.1.72.Final!netty-handler.jar (263ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-handler-proxy/4.1.72.Final/netty-handler-proxy-4.1.72.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-handler-proxy;4.1.72.Final!netty-handler-proxy.jar (33ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-buffer/4.1.72.Final/netty-buffer-4.1.72.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-buffer;4.1.72.Final!netty-buffer.jar (94ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-codec-http/4.1.72.Final/netty-codec-http-4.1.72.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-codec-http;4.1.72.Final!netty-codec-http.jar (224ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-codec-http2/4.1.72.Final/netty-codec-http2-4.1.72.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-codec-http2;4.1.72.Final!netty-codec-http2.jar (210ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-transport-native-unix-common/4.1.72.Final/netty-transport-native-unix-common-4.1.72.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-transport-native-unix-common;4.1.72.Final!netty-transport-native-unix-common.jar (49ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-transport-native-epoll/4.1.72.Final/netty-transport-native-epoll-4.1.72.Final-linux-x86_64.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-transport-native-epoll;4.1.72.Final!netty-transport-native-epoll.jar (29ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-transport-native-kqueue/4.1.72.Final/netty-transport-native-kqueue-4.1.72.Final-osx-x86_64.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-transport-native-kqueue;4.1.72.Final!netty-transport-native-kqueue.jar (33ms)\n",
      "downloading https://repo1.maven.org/maven2/io/projectreactor/netty/reactor-netty-http/1.0.14/reactor-netty-http-1.0.14.jar ...\n",
      "\t[SUCCESSFUL ] io.projectreactor.netty#reactor-netty-http;1.0.14!reactor-netty-http.jar (110ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-common/4.1.72.Final/netty-common-4.1.72.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-common;4.1.72.Final!netty-common.jar (198ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-resolver/4.1.72.Final/netty-resolver-4.1.72.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-resolver;4.1.72.Final!netty-resolver.jar (27ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-transport/4.1.72.Final/netty-transport-4.1.72.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-transport;4.1.72.Final!netty-transport.jar (172ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-codec/4.1.72.Final/netty-codec-4.1.72.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-codec;4.1.72.Final!netty-codec.jar (115ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-codec-socks/4.1.72.Final/netty-codec-socks-4.1.72.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-codec-socks;4.1.72.Final!netty-codec-socks.jar (48ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-transport-classes-epoll/4.1.72.Final/netty-transport-classes-epoll-4.1.72.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-transport-classes-epoll;4.1.72.Final!netty-transport-classes-epoll.jar (57ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-transport-classes-kqueue/4.1.72.Final/netty-transport-classes-kqueue-4.1.72.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-transport-classes-kqueue;4.1.72.Final!netty-transport-classes-kqueue.jar (77ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-resolver-dns/4.1.72.Final/netty-resolver-dns-4.1.72.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-resolver-dns;4.1.72.Final!netty-resolver-dns.jar (76ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-resolver-dns-native-macos/4.1.72.Final/netty-resolver-dns-native-macos-4.1.72.Final-osx-x86_64.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-resolver-dns-native-macos;4.1.72.Final!netty-resolver-dns-native-macos.jar (34ms)\n",
      "downloading https://repo1.maven.org/maven2/io/projectreactor/netty/reactor-netty-core/1.0.14/reactor-netty-core-1.0.14.jar ...\n",
      "\t[SUCCESSFUL ] io.projectreactor.netty#reactor-netty-core;1.0.14!reactor-netty-core.jar (164ms)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading https://repo1.maven.org/maven2/io/netty/netty-codec-dns/4.1.72.Final/netty-codec-dns-4.1.72.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-codec-dns;4.1.72.Final!netty-codec-dns.jar (38ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty-resolver-dns-classes-macos/4.1.72.Final/netty-resolver-dns-classes-macos-4.1.72.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty-resolver-dns-classes-macos;4.1.72.Final!netty-resolver-dns-classes-macos.jar (25ms)\n",
      "downloading https://repo1.maven.org/maven2/com/github/vowpalwabbit/vw-jni/8.9.1/vw-jni-8.9.1.jar ...\n",
      "\t[SUCCESSFUL ] com.github.vowpalwabbit#vw-jni;8.9.1!vw-jni.jar (1537ms)\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/ml/lightgbm/lightgbmlib/3.2.110/lightgbmlib-3.2.110.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.ml.lightgbm#lightgbmlib;3.2.110!lightgbmlib.jar (1174ms)\n",
      ":: resolution report :: resolve 27069ms :: artifacts dl 134742ms\n",
      "\t:: modules in use:\n",
      "\tcom.azure#azure-ai-textanalytics;5.1.6 from central in [default]\n",
      "\tcom.azure#azure-core;1.25.0 from central in [default]\n",
      "\tcom.azure#azure-core-http-netty;1.11.7 from central in [default]\n",
      "\tcom.azure#azure-storage-blob;12.14.4 from central in [default]\n",
      "\tcom.azure#azure-storage-common;12.14.3 from central in [default]\n",
      "\tcom.azure#azure-storage-internal-avro;12.1.4 from central in [default]\n",
      "\tcom.beust#jcommander;1.27 from central in [default]\n",
      "\tcom.chuusai#shapeless_2.12;2.3.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.13.1 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.13.1 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.13.1 from central in [default]\n",
      "\tcom.fasterxml.jackson.dataformat#jackson-dataformat-xml;2.13.1 from central in [default]\n",
      "\tcom.fasterxml.jackson.datatype#jackson-datatype-jsr310;2.13.1 from central in [default]\n",
      "\tcom.fasterxml.woodstox#woodstox-core;6.2.7 from central in [default]\n",
      "\tcom.github.vowpalwabbit#vw-jni;8.9.1 from central in [default]\n",
      "\tcom.jcraft#jsch;0.1.54 from central in [default]\n",
      "\tcom.linkedin.isolation-forest#isolation-forest_3.2.0_2.12;2.0.8 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-cognitive_2.12;0.10.1 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-core_2.12;0.10.1 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-deep-learning_2.12;0.10.1 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-lightgbm_2.12;0.10.1 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-opencv_2.12;0.10.1 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-vw_2.12;0.10.1 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml_2.12;0.10.1 from central in [default]\n",
      "\tcom.microsoft.cntk#cntk;2.4 from central in [default]\n",
      "\tcom.microsoft.cognitiveservices.speech#client-jar-sdk;1.14.0 from central in [default]\n",
      "\tcom.microsoft.ml.lightgbm#lightgbmlib;3.2.110 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime_gpu;1.8.1 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.10 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.2 from central in [default]\n",
      "\tio.netty#netty-buffer;4.1.72.Final from central in [default]\n",
      "\tio.netty#netty-codec;4.1.72.Final from central in [default]\n",
      "\tio.netty#netty-codec-dns;4.1.72.Final from central in [default]\n",
      "\tio.netty#netty-codec-http;4.1.72.Final from central in [default]\n",
      "\tio.netty#netty-codec-http2;4.1.72.Final from central in [default]\n",
      "\tio.netty#netty-codec-socks;4.1.72.Final from central in [default]\n",
      "\tio.netty#netty-common;4.1.72.Final from central in [default]\n",
      "\tio.netty#netty-handler;4.1.72.Final from central in [default]\n",
      "\tio.netty#netty-handler-proxy;4.1.72.Final from central in [default]\n",
      "\tio.netty#netty-resolver;4.1.72.Final from central in [default]\n",
      "\tio.netty#netty-resolver-dns;4.1.72.Final from central in [default]\n",
      "\tio.netty#netty-resolver-dns-classes-macos;4.1.72.Final from central in [default]\n",
      "\tio.netty#netty-resolver-dns-native-macos;4.1.72.Final from central in [default]\n",
      "\tio.netty#netty-tcnative-boringssl-static;2.0.46.Final from central in [default]\n",
      "\tio.netty#netty-tcnative-classes;2.0.46.Final from central in [default]\n",
      "\tio.netty#netty-transport;4.1.72.Final from central in [default]\n",
      "\tio.netty#netty-transport-classes-epoll;4.1.72.Final from central in [default]\n",
      "\tio.netty#netty-transport-classes-kqueue;4.1.72.Final from central in [default]\n",
      "\tio.netty#netty-transport-native-epoll;4.1.72.Final from central in [default]\n",
      "\tio.netty#netty-transport-native-kqueue;4.1.72.Final from central in [default]\n",
      "\tio.netty#netty-transport-native-unix-common;4.1.72.Final from central in [default]\n",
      "\tio.projectreactor#reactor-core;3.4.13 from central in [default]\n",
      "\tio.projectreactor.netty#reactor-netty-core;1.0.14 from central in [default]\n",
      "\tio.projectreactor.netty#reactor-netty-http;1.0.14 from central in [default]\n",
      "\tio.spray#spray-json_2.12;1.3.5 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.6 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.10 from central in [default]\n",
      "\torg.apache.httpcomponents#httpmime;4.5.6 from central in [default]\n",
      "\torg.apache.spark#spark-avro_2.12;3.2.0 from central in [default]\n",
      "\torg.beanshell#bsh;2.0b4 from central in [default]\n",
      "\torg.codehaus.woodstox#stax2-api;4.2.1 from central in [default]\n",
      "\torg.openpnp#opencv;3.2.0-1 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.4 from central in [default]\n",
      "\torg.scalactic#scalactic_2.12;3.0.5 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.32 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.testng#testng;6.8.8 from central in [default]\n",
      "\torg.tukaani#xz;1.8 from central in [default]\n",
      "\torg.typelevel#macro-compat_2.12;1.1.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   70  |   67  |   67  |   0   ||   70  |   67  |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f28fea49-eb9a-4093-8359-d7855837196e\n",
      "\tconfs: [default]\n",
      "\t67 artifacts copied, 3 already retrieved (428562kB/286ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/01 15:12:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import socket\n",
    "import os\n",
    "\n",
    "spark_master = os.environ.get('SPARK_MASTER') # \"spark://spark-master:7077\" \n",
    "driver_host = socket.gethostbyname(socket.gethostname()) # setting driver host is important in k8s mode, ortherwise excutors cannot find diver host\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(spark_master)\\\n",
    "    .appName(\"lightGBM\") \\\n",
    "    .config(\"spark.driver.host\", driver_host) \\\n",
    "    .config(\"spark.jars.packages\", \"com.microsoft.azure:synapseml_2.12:0.10.1\") \\\n",
    "    .config(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\") \\\n",
    "    .getOrCreate()\n",
    "import synapse.ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1cf0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synapse.ml.lightgbm import *\n",
    "\n",
    "lgbmClassifier = (LightGBMClassifier()\n",
    "      .setFeaturesCol(\"features\")\n",
    "      .setRawPredictionCol(\"rawPrediction\")\n",
    "      .setDefaultListenPort(12402)\n",
    "      .setNumLeaves(5)\n",
    "      .setNumIterations(10)\n",
    "      .setObjective(\"binary\")\n",
    "      .setLabelCol(\"labels\")\n",
    "      .setLeafPredictionCol(\"leafPrediction\")\n",
    "      .setFeaturesShapCol(\"featuresShap\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f484ee97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LightGBMClassifier in module synapse.ml.lightgbm.LightGBMClassifier object:\n",
      "\n",
      "class LightGBMClassifier(synapse.ml.core.schema.Utils.ComplexParamsMixin, pyspark.ml.util.JavaMLReadable, pyspark.ml.util.JavaMLWritable, pyspark.ml.wrapper.JavaEstimator)\n",
      " |  LightGBMClassifier(java_obj=None, baggingFraction=1.0, baggingFreq=0, baggingSeed=3, binSampleCount=200000, boostFromAverage=True, boostingType='gbdt', catSmooth=10.0, categoricalSlotIndexes=[], categoricalSlotNames=[], catl2=10.0, chunkSize=10000, dataRandomSeed=1, defaultListenPort=12400, deterministic=False, driverListenPort=0, dropRate=0.1, dropSeed=4, earlyStoppingRound=0, executionMode='bulk', extraSeed=6, featureFraction=1.0, featureFractionByNode=None, featureFractionSeed=2, featuresCol='features', featuresShapCol='', fobj=None, improvementTolerance=0.0, initScoreCol=None, isEnableSparse=True, isProvideTrainingMetric=False, isUnbalance=False, labelCol='label', lambdaL1=0.0, lambdaL2=0.0, leafPredictionCol='', learningRate=0.1, matrixType='auto', maxBin=255, maxBinByFeature=[], maxCatThreshold=32, maxCatToOnehot=4, maxDeltaStep=0.0, maxDepth=-1, maxDrop=50, metric='', microBatchSize=1, minDataInLeaf=20, minDataPerBin=3, minDataPerGroup=100, minGainToSplit=0.0, minSumHessianInLeaf=0.001, modelString='', monotoneConstraints=[], monotoneConstraintsMethod='basic', monotonePenalty=0.0, negBaggingFraction=1.0, numBatches=0, numIterations=100, numLeaves=31, numTasks=0, numThreads=0, objective='binary', objectiveSeed=5, otherRate=0.1, parallelism='data_parallel', passThroughArgs='', posBaggingFraction=1.0, predictDisableShapeCheck=False, predictionCol='prediction', probabilityCol='probability', rawPredictionCol='rawPrediction', repartitionByGroupingColumn=True, seed=None, skipDrop=0.5, slotNames=[], thresholds=None, timeout=1200.0, topK=20, topRate=0.2, uniformDrop=False, useBarrierExecutionMode=False, useMissing=True, useSingleDatasetMode=True, validationIndicatorCol=None, verbosity=-1, weightCol=None, xGBoostDartMode=False, zeroAsMissing=False)\n",
      " |  \n",
      " |  Args:\n",
      " |      baggingFraction (float): Bagging fraction\n",
      " |      baggingFreq (int): Bagging frequency\n",
      " |      baggingSeed (int): Bagging seed\n",
      " |      binSampleCount (int): Number of samples considered at computing histogram bins\n",
      " |      boostFromAverage (bool): Adjusts initial score to the mean of labels for faster convergence\n",
      " |      boostingType (str): Default gbdt = traditional Gradient Boosting Decision Tree. Options are: gbdt, gbrt, rf (Random Forest), random_forest, dart (Dropouts meet Multiple Additive Regression Trees), goss (Gradient-based One-Side Sampling). \n",
      " |      catSmooth (float): this can reduce the effect of noises in categorical features, especially for categories with few data\n",
      " |      categoricalSlotIndexes (list): List of categorical column indexes, the slot index in the features column\n",
      " |      categoricalSlotNames (list): List of categorical column slot names, the slot name in the features column\n",
      " |      catl2 (float): L2 regularization in categorical split\n",
      " |      chunkSize (int): Advanced parameter to specify the chunk size for copying Java data to native.  If set too high, memory may be wasted, but if set too low, performance may be reduced during data copy.If dataset size is known beforehand, set to the number of rows in the dataset.\n",
      " |      dataRandomSeed (int): Random seed for sampling data to construct histogram bins.\n",
      " |      defaultListenPort (int): The default listen port on executors, used for testing\n",
      " |      deterministic (bool): Used only with cpu devide type. Setting this to true should ensure stable results when using the same data and the same parameters.  Note: setting this to true may slow down training.  To avoid potential instability due to numerical issues, please set force_col_wise=true or force_row_wise=true when setting deterministic=true\n",
      " |      driverListenPort (int): The listen port on a driver. Default value is 0 (random)\n",
      " |      dropRate (float): Dropout rate: a fraction of previous trees to drop during the dropout\n",
      " |      dropSeed (int): Random seed to choose dropping models. Only used in dart.\n",
      " |      earlyStoppingRound (int): Early stopping round\n",
      " |      executionMode (str): Specify how LightGBM is executed.  Values can be streaming, bulk. Default is bulk.\n",
      " |      extraSeed (int): Random seed for selecting threshold when extra_trees is true\n",
      " |      featureFraction (float): Feature fraction\n",
      " |      featureFractionByNode (float): Feature fraction by node\n",
      " |      featureFractionSeed (int): Feature fraction seed\n",
      " |      featuresCol (str): features column name\n",
      " |      featuresShapCol (str): Output SHAP vector column name after prediction containing the feature contribution values\n",
      " |      fobj (object): Customized objective function. Should accept two parameters: preds, train_data, and return (grad, hess).\n",
      " |      improvementTolerance (float): Tolerance to consider improvement in metric\n",
      " |      initScoreCol (str): The name of the initial score column, used for continued training\n",
      " |      isEnableSparse (bool): Used to enable/disable sparse optimization\n",
      " |      isProvideTrainingMetric (bool): Whether output metric result over training dataset.\n",
      " |      isUnbalance (bool): Set to true if training data is unbalanced in binary classification scenario\n",
      " |      labelCol (str): label column name\n",
      " |      lambdaL1 (float): L1 regularization\n",
      " |      lambdaL2 (float): L2 regularization\n",
      " |      leafPredictionCol (str): Predicted leaf indices's column name\n",
      " |      learningRate (float): Learning rate or shrinkage rate\n",
      " |      matrixType (str): Advanced parameter to specify whether the native lightgbm matrix constructed should be sparse or dense.  Values can be auto, sparse or dense. Default value is auto, which samples first ten rows to determine type.\n",
      " |      maxBin (int): Max bin\n",
      " |      maxBinByFeature (list): Max number of bins for each feature\n",
      " |      maxCatThreshold (int): limit number of split points considered for categorical features\n",
      " |      maxCatToOnehot (int): when number of categories of one feature smaller than or equal to this, one-vs-other split algorithm will be used\n",
      " |      maxDeltaStep (float): Used to limit the max output of tree leaves\n",
      " |      maxDepth (int): Max depth\n",
      " |      maxDrop (int): Max number of dropped trees during one boosting iteration\n",
      " |      metric (str): Metrics to be evaluated on the evaluation data.  Options are: empty string or not specified means that metric corresponding to specified objective will be used (this is possible only for pre-defined objective functions, otherwise no evaluation metric will be added). None (string, not a None value) means that no metric will be registered, aliases: na, null, custom. l1, absolute loss, aliases: mean_absolute_error, mae, regression_l1. l2, square loss, aliases: mean_squared_error, mse, regression_l2, regression. rmse, root square loss, aliases: root_mean_squared_error, l2_root. quantile, Quantile regression. mape, MAPE loss, aliases: mean_absolute_percentage_error. huber, Huber loss. fair, Fair loss. poisson, negative log-likelihood for Poisson regression. gamma, negative log-likelihood for Gamma regression. gamma_deviance, residual deviance for Gamma regression. tweedie, negative log-likelihood for Tweedie regression. ndcg, NDCG, aliases: lambdarank. map, MAP, aliases: mean_average_precision. auc, AUC. binary_logloss, log loss, aliases: binary. binary_error, for one sample: 0 for correct classification, 1 for error classification. multi_logloss, log loss for multi-class classification, aliases: multiclass, softmax, multiclassova, multiclass_ova, ova, ovr. multi_error, error rate for multi-class classification. cross_entropy, cross-entropy (with optional linear weights), aliases: xentropy. cross_entropy_lambda, intensity-weighted cross-entropy, aliases: xentlambda. kullback_leibler, Kullback-Leibler divergence, aliases: kldiv. \n",
      " |      microBatchSize (int): Specify how many elements are sent in a streaming micro-batch.\n",
      " |      minDataInLeaf (int): Minimal number of data in one leaf. Can be used to deal with over-fitting.\n",
      " |      minDataPerBin (int): Minimal number of data inside one bin\n",
      " |      minDataPerGroup (int): minimal number of data per categorical group\n",
      " |      minGainToSplit (float): The minimal gain to perform split\n",
      " |      minSumHessianInLeaf (float): Minimal sum hessian in one leaf\n",
      " |      modelString (str): LightGBM model to retrain\n",
      " |      monotoneConstraints (list): used for constraints of monotonic features. 1 means increasing, -1 means decreasing, 0 means non-constraint. Specify all features in order.\n",
      " |      monotoneConstraintsMethod (str): Monotone constraints method. basic, intermediate, or advanced.\n",
      " |      monotonePenalty (float): A penalization parameter X forbids any monotone splits on the first X (rounded down) level(s) of the tree.\n",
      " |      negBaggingFraction (float): Negative Bagging fraction\n",
      " |      numBatches (int): If greater than 0, splits data into separate batches during training\n",
      " |      numIterations (int): Number of iterations, LightGBM constructs num_class * num_iterations trees\n",
      " |      numLeaves (int): Number of leaves\n",
      " |      numTasks (int): Advanced parameter to specify the number of tasks.  SynapseML tries to guess this based on cluster configuration, but this parameter can be used to override.\n",
      " |      numThreads (int): Number of threads per executor for LightGBM. For the best speed, set this to the number of real CPU cores.\n",
      " |      objective (str): The Objective. For regression applications, this can be: regression_l2, regression_l1, huber, fair, poisson, quantile, mape, gamma or tweedie. For classification applications, this can be: binary, multiclass, or multiclassova. \n",
      " |      objectiveSeed (int): Random seed for objectives, if random process is needed.  Currently used only for rank_xendcg objective.\n",
      " |      otherRate (float): The retain ratio of small gradient data. Only used in goss.\n",
      " |      parallelism (str): Tree learner parallelism, can be set to data_parallel or voting_parallel\n",
      " |      passThroughArgs (str): Direct string to pass through to LightGBM library (appended with other explicitly set params). Will override any parameters given with explicit setters. Can include multiple parameters in one string.\n",
      " |      posBaggingFraction (float): Positive Bagging fraction\n",
      " |      predictDisableShapeCheck (bool): control whether or not LightGBM raises an error when you try to predict on data with a different number of features than the training data\n",
      " |      predictionCol (str): prediction column name\n",
      " |      probabilityCol (str): Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities\n",
      " |      rawPredictionCol (str): raw prediction (a.k.a. confidence) column name\n",
      " |      repartitionByGroupingColumn (bool): Repartition training data according to grouping column, on by default.\n",
      " |      seed (int): Main seed, used to generate other seeds\n",
      " |      skipDrop (float): Probability of skipping the dropout procedure during a boosting iteration\n",
      " |      slotNames (list): List of slot names in the features column\n",
      " |      thresholds (list): Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0 excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold\n",
      " |      timeout (float): Timeout in seconds\n",
      " |      topK (int): The top_k value used in Voting parallel, set this to larger value for more accurate result, but it will slow down the training speed. It should be greater than 0\n",
      " |      topRate (float): The retain ratio of large gradient data. Only used in goss.\n",
      " |      uniformDrop (bool): Set this to true to use uniform drop in dart mode\n",
      " |      useBarrierExecutionMode (bool): Barrier execution mode which uses a barrier stage, off by default.\n",
      " |      useMissing (bool): Set this to false to disable the special handle of missing value\n",
      " |      useSingleDatasetMode (bool): Use single dataset execution mode to create a single native dataset per executor (singleton) to reduce memory and communication overhead.\n",
      " |      validationIndicatorCol (str): Indicates whether the row is for training or validation\n",
      " |      verbosity (int): Verbosity where lt 0 is Fatal, eq 0 is Error, eq 1 is Info, gt 1 is Debug\n",
      " |      weightCol (str): The name of the weight column\n",
      " |      xGBoostDartMode (bool): Set this to true to use xgboost dart mode\n",
      " |      zeroAsMissing (bool): Set to true to treat all zero as missing values (including the unshown values in LibSVM / sparse matrices). Set to false to use na for representing missing values\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LightGBMClassifier\n",
      " |      synapse.ml.core.schema.Utils.ComplexParamsMixin\n",
      " |      pyspark.ml.util.JavaMLReadable\n",
      " |      pyspark.ml.util.MLReadable\n",
      " |      pyspark.ml.util.JavaMLWritable\n",
      " |      pyspark.ml.util.MLWritable\n",
      " |      pyspark.ml.wrapper.JavaEstimator\n",
      " |      pyspark.ml.wrapper.JavaParams\n",
      " |      pyspark.ml.wrapper.JavaWrapper\n",
      " |      pyspark.ml.base.Estimator\n",
      " |      pyspark.ml.param.Params\n",
      " |      pyspark.ml.util.Identifiable\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, java_obj=None, baggingFraction=1.0, baggingFreq=0, baggingSeed=3, binSampleCount=200000, boostFromAverage=True, boostingType='gbdt', catSmooth=10.0, categoricalSlotIndexes=[], categoricalSlotNames=[], catl2=10.0, chunkSize=10000, dataRandomSeed=1, defaultListenPort=12400, deterministic=False, driverListenPort=0, dropRate=0.1, dropSeed=4, earlyStoppingRound=0, executionMode='bulk', extraSeed=6, featureFraction=1.0, featureFractionByNode=None, featureFractionSeed=2, featuresCol='features', featuresShapCol='', fobj=None, improvementTolerance=0.0, initScoreCol=None, isEnableSparse=True, isProvideTrainingMetric=False, isUnbalance=False, labelCol='label', lambdaL1=0.0, lambdaL2=0.0, leafPredictionCol='', learningRate=0.1, matrixType='auto', maxBin=255, maxBinByFeature=[], maxCatThreshold=32, maxCatToOnehot=4, maxDeltaStep=0.0, maxDepth=-1, maxDrop=50, metric='', microBatchSize=1, minDataInLeaf=20, minDataPerBin=3, minDataPerGroup=100, minGainToSplit=0.0, minSumHessianInLeaf=0.001, modelString='', monotoneConstraints=[], monotoneConstraintsMethod='basic', monotonePenalty=0.0, negBaggingFraction=1.0, numBatches=0, numIterations=100, numLeaves=31, numTasks=0, numThreads=0, objective='binary', objectiveSeed=5, otherRate=0.1, parallelism='data_parallel', passThroughArgs='', posBaggingFraction=1.0, predictDisableShapeCheck=False, predictionCol='prediction', probabilityCol='probability', rawPredictionCol='rawPrediction', repartitionByGroupingColumn=True, seed=None, skipDrop=0.5, slotNames=[], thresholds=None, timeout=1200.0, topK=20, topRate=0.2, uniformDrop=False, useBarrierExecutionMode=False, useMissing=True, useSingleDatasetMode=True, validationIndicatorCol=None, verbosity=-1, weightCol=None, xGBoostDartMode=False, zeroAsMissing=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  getBaggingFraction(self)\n",
      " |      Returns:\n",
      " |          baggingFraction: Bagging fraction\n",
      " |  \n",
      " |  getBaggingFreq(self)\n",
      " |      Returns:\n",
      " |          baggingFreq: Bagging frequency\n",
      " |  \n",
      " |  getBaggingSeed(self)\n",
      " |      Returns:\n",
      " |          baggingSeed: Bagging seed\n",
      " |  \n",
      " |  getBinSampleCount(self)\n",
      " |      Returns:\n",
      " |          binSampleCount: Number of samples considered at computing histogram bins\n",
      " |  \n",
      " |  getBoostFromAverage(self)\n",
      " |      Returns:\n",
      " |          boostFromAverage: Adjusts initial score to the mean of labels for faster convergence\n",
      " |  \n",
      " |  getBoostingType(self)\n",
      " |      Returns:\n",
      " |          boostingType: Default gbdt = traditional Gradient Boosting Decision Tree. Options are: gbdt, gbrt, rf (Random Forest), random_forest, dart (Dropouts meet Multiple Additive Regression Trees), goss (Gradient-based One-Side Sampling).\n",
      " |  \n",
      " |  getCatSmooth(self)\n",
      " |      Returns:\n",
      " |          catSmooth: this can reduce the effect of noises in categorical features, especially for categories with few data\n",
      " |  \n",
      " |  getCategoricalSlotIndexes(self)\n",
      " |      Returns:\n",
      " |          categoricalSlotIndexes: List of categorical column indexes, the slot index in the features column\n",
      " |  \n",
      " |  getCategoricalSlotNames(self)\n",
      " |      Returns:\n",
      " |          categoricalSlotNames: List of categorical column slot names, the slot name in the features column\n",
      " |  \n",
      " |  getCatl2(self)\n",
      " |      Returns:\n",
      " |          catl2: L2 regularization in categorical split\n",
      " |  \n",
      " |  getChunkSize(self)\n",
      " |      Returns:\n",
      " |          chunkSize: Advanced parameter to specify the chunk size for copying Java data to native.  If set too high, memory may be wasted, but if set too low, performance may be reduced during data copy.If dataset size is known beforehand, set to the number of rows in the dataset.\n",
      " |  \n",
      " |  getDataRandomSeed(self)\n",
      " |      Returns:\n",
      " |          dataRandomSeed: Random seed for sampling data to construct histogram bins.\n",
      " |  \n",
      " |  getDefaultListenPort(self)\n",
      " |      Returns:\n",
      " |          defaultListenPort: The default listen port on executors, used for testing\n",
      " |  \n",
      " |  getDeterministic(self)\n",
      " |      Returns:\n",
      " |          deterministic: Used only with cpu devide type. Setting this to true should ensure stable results when using the same data and the same parameters.  Note: setting this to true may slow down training.  To avoid potential instability due to numerical issues, please set force_col_wise=true or force_row_wise=true when setting deterministic=true\n",
      " |  \n",
      " |  getDriverListenPort(self)\n",
      " |      Returns:\n",
      " |          driverListenPort: The listen port on a driver. Default value is 0 (random)\n",
      " |  \n",
      " |  getDropRate(self)\n",
      " |      Returns:\n",
      " |          dropRate: Dropout rate: a fraction of previous trees to drop during the dropout\n",
      " |  \n",
      " |  getDropSeed(self)\n",
      " |      Returns:\n",
      " |          dropSeed: Random seed to choose dropping models. Only used in dart.\n",
      " |  \n",
      " |  getEarlyStoppingRound(self)\n",
      " |      Returns:\n",
      " |          earlyStoppingRound: Early stopping round\n",
      " |  \n",
      " |  getExecutionMode(self)\n",
      " |      Returns:\n",
      " |          executionMode: Specify how LightGBM is executed.  Values can be streaming, bulk. Default is bulk.\n",
      " |  \n",
      " |  getExtraSeed(self)\n",
      " |      Returns:\n",
      " |          extraSeed: Random seed for selecting threshold when extra_trees is true\n",
      " |  \n",
      " |  getFeatureFraction(self)\n",
      " |      Returns:\n",
      " |          featureFraction: Feature fraction\n",
      " |  \n",
      " |  getFeatureFractionByNode(self)\n",
      " |      Returns:\n",
      " |          featureFractionByNode: Feature fraction by node\n",
      " |  \n",
      " |  getFeatureFractionSeed(self)\n",
      " |      Returns:\n",
      " |          featureFractionSeed: Feature fraction seed\n",
      " |  \n",
      " |  getFeaturesCol(self)\n",
      " |      Returns:\n",
      " |          featuresCol: features column name\n",
      " |  \n",
      " |  getFeaturesShapCol(self)\n",
      " |      Returns:\n",
      " |          featuresShapCol: Output SHAP vector column name after prediction containing the feature contribution values\n",
      " |  \n",
      " |  getFobj(self)\n",
      " |      Returns:\n",
      " |          fobj: Customized objective function. Should accept two parameters: preds, train_data, and return (grad, hess).\n",
      " |  \n",
      " |  getImprovementTolerance(self)\n",
      " |      Returns:\n",
      " |          improvementTolerance: Tolerance to consider improvement in metric\n",
      " |  \n",
      " |  getInitScoreCol(self)\n",
      " |      Returns:\n",
      " |          initScoreCol: The name of the initial score column, used for continued training\n",
      " |  \n",
      " |  getIsEnableSparse(self)\n",
      " |      Returns:\n",
      " |          isEnableSparse: Used to enable/disable sparse optimization\n",
      " |  \n",
      " |  getIsProvideTrainingMetric(self)\n",
      " |      Returns:\n",
      " |          isProvideTrainingMetric: Whether output metric result over training dataset.\n",
      " |  \n",
      " |  getIsUnbalance(self)\n",
      " |      Returns:\n",
      " |          isUnbalance: Set to true if training data is unbalanced in binary classification scenario\n",
      " |  \n",
      " |  getLabelCol(self)\n",
      " |      Returns:\n",
      " |          labelCol: label column name\n",
      " |  \n",
      " |  getLambdaL1(self)\n",
      " |      Returns:\n",
      " |          lambdaL1: L1 regularization\n",
      " |  \n",
      " |  getLambdaL2(self)\n",
      " |      Returns:\n",
      " |          lambdaL2: L2 regularization\n",
      " |  \n",
      " |  getLeafPredictionCol(self)\n",
      " |      Returns:\n",
      " |          leafPredictionCol: Predicted leaf indices's column name\n",
      " |  \n",
      " |  getLearningRate(self)\n",
      " |      Returns:\n",
      " |          learningRate: Learning rate or shrinkage rate\n",
      " |  \n",
      " |  getMatrixType(self)\n",
      " |      Returns:\n",
      " |          matrixType: Advanced parameter to specify whether the native lightgbm matrix constructed should be sparse or dense.  Values can be auto, sparse or dense. Default value is auto, which samples first ten rows to determine type.\n",
      " |  \n",
      " |  getMaxBin(self)\n",
      " |      Returns:\n",
      " |          maxBin: Max bin\n",
      " |  \n",
      " |  getMaxBinByFeature(self)\n",
      " |      Returns:\n",
      " |          maxBinByFeature: Max number of bins for each feature\n",
      " |  \n",
      " |  getMaxCatThreshold(self)\n",
      " |      Returns:\n",
      " |          maxCatThreshold: limit number of split points considered for categorical features\n",
      " |  \n",
      " |  getMaxCatToOnehot(self)\n",
      " |      Returns:\n",
      " |          maxCatToOnehot: when number of categories of one feature smaller than or equal to this, one-vs-other split algorithm will be used\n",
      " |  \n",
      " |  getMaxDeltaStep(self)\n",
      " |      Returns:\n",
      " |          maxDeltaStep: Used to limit the max output of tree leaves\n",
      " |  \n",
      " |  getMaxDepth(self)\n",
      " |      Returns:\n",
      " |          maxDepth: Max depth\n",
      " |  \n",
      " |  getMaxDrop(self)\n",
      " |      Returns:\n",
      " |          maxDrop: Max number of dropped trees during one boosting iteration\n",
      " |  \n",
      " |  getMetric(self)\n",
      " |      Returns:\n",
      " |          metric: Metrics to be evaluated on the evaluation data.  Options are: empty string or not specified means that metric corresponding to specified objective will be used (this is possible only for pre-defined objective functions, otherwise no evaluation metric will be added). None (string, not a None value) means that no metric will be registered, aliases: na, null, custom. l1, absolute loss, aliases: mean_absolute_error, mae, regression_l1. l2, square loss, aliases: mean_squared_error, mse, regression_l2, regression. rmse, root square loss, aliases: root_mean_squared_error, l2_root. quantile, Quantile regression. mape, MAPE loss, aliases: mean_absolute_percentage_error. huber, Huber loss. fair, Fair loss. poisson, negative log-likelihood for Poisson regression. gamma, negative log-likelihood for Gamma regression. gamma_deviance, residual deviance for Gamma regression. tweedie, negative log-likelihood for Tweedie regression. ndcg, NDCG, aliases: lambdarank. map, MAP, aliases: mean_average_precision. auc, AUC. binary_logloss, log loss, aliases: binary. binary_error, for one sample: 0 for correct classification, 1 for error classification. multi_logloss, log loss for multi-class classification, aliases: multiclass, softmax, multiclassova, multiclass_ova, ova, ovr. multi_error, error rate for multi-class classification. cross_entropy, cross-entropy (with optional linear weights), aliases: xentropy. cross_entropy_lambda, intensity-weighted cross-entropy, aliases: xentlambda. kullback_leibler, Kullback-Leibler divergence, aliases: kldiv.\n",
      " |  \n",
      " |  getMicroBatchSize(self)\n",
      " |      Returns:\n",
      " |          microBatchSize: Specify how many elements are sent in a streaming micro-batch.\n",
      " |  \n",
      " |  getMinDataInLeaf(self)\n",
      " |      Returns:\n",
      " |          minDataInLeaf: Minimal number of data in one leaf. Can be used to deal with over-fitting.\n",
      " |  \n",
      " |  getMinDataPerBin(self)\n",
      " |      Returns:\n",
      " |          minDataPerBin: Minimal number of data inside one bin\n",
      " |  \n",
      " |  getMinDataPerGroup(self)\n",
      " |      Returns:\n",
      " |          minDataPerGroup: minimal number of data per categorical group\n",
      " |  \n",
      " |  getMinGainToSplit(self)\n",
      " |      Returns:\n",
      " |          minGainToSplit: The minimal gain to perform split\n",
      " |  \n",
      " |  getMinSumHessianInLeaf(self)\n",
      " |      Returns:\n",
      " |          minSumHessianInLeaf: Minimal sum hessian in one leaf\n",
      " |  \n",
      " |  getModelString(self)\n",
      " |      Returns:\n",
      " |          modelString: LightGBM model to retrain\n",
      " |  \n",
      " |  getMonotoneConstraints(self)\n",
      " |      Returns:\n",
      " |          monotoneConstraints: used for constraints of monotonic features. 1 means increasing, -1 means decreasing, 0 means non-constraint. Specify all features in order.\n",
      " |  \n",
      " |  getMonotoneConstraintsMethod(self)\n",
      " |      Returns:\n",
      " |          monotoneConstraintsMethod: Monotone constraints method. basic, intermediate, or advanced.\n",
      " |  \n",
      " |  getMonotonePenalty(self)\n",
      " |      Returns:\n",
      " |          monotonePenalty: A penalization parameter X forbids any monotone splits on the first X (rounded down) level(s) of the tree.\n",
      " |  \n",
      " |  getNegBaggingFraction(self)\n",
      " |      Returns:\n",
      " |          negBaggingFraction: Negative Bagging fraction\n",
      " |  \n",
      " |  getNumBatches(self)\n",
      " |      Returns:\n",
      " |          numBatches: If greater than 0, splits data into separate batches during training\n",
      " |  \n",
      " |  getNumIterations(self)\n",
      " |      Returns:\n",
      " |          numIterations: Number of iterations, LightGBM constructs num_class * num_iterations trees\n",
      " |  \n",
      " |  getNumLeaves(self)\n",
      " |      Returns:\n",
      " |          numLeaves: Number of leaves\n",
      " |  \n",
      " |  getNumTasks(self)\n",
      " |      Returns:\n",
      " |          numTasks: Advanced parameter to specify the number of tasks.  SynapseML tries to guess this based on cluster configuration, but this parameter can be used to override.\n",
      " |  \n",
      " |  getNumThreads(self)\n",
      " |      Returns:\n",
      " |          numThreads: Number of threads per executor for LightGBM. For the best speed, set this to the number of real CPU cores.\n",
      " |  \n",
      " |  getObjective(self)\n",
      " |      Returns:\n",
      " |          objective: The Objective. For regression applications, this can be: regression_l2, regression_l1, huber, fair, poisson, quantile, mape, gamma or tweedie. For classification applications, this can be: binary, multiclass, or multiclassova.\n",
      " |  \n",
      " |  getObjectiveSeed(self)\n",
      " |      Returns:\n",
      " |          objectiveSeed: Random seed for objectives, if random process is needed.  Currently used only for rank_xendcg objective.\n",
      " |  \n",
      " |  getOtherRate(self)\n",
      " |      Returns:\n",
      " |          otherRate: The retain ratio of small gradient data. Only used in goss.\n",
      " |  \n",
      " |  getParallelism(self)\n",
      " |      Returns:\n",
      " |          parallelism: Tree learner parallelism, can be set to data_parallel or voting_parallel\n",
      " |  \n",
      " |  getPassThroughArgs(self)\n",
      " |      Returns:\n",
      " |          passThroughArgs: Direct string to pass through to LightGBM library (appended with other explicitly set params). Will override any parameters given with explicit setters. Can include multiple parameters in one string.\n",
      " |  \n",
      " |  getPosBaggingFraction(self)\n",
      " |      Returns:\n",
      " |          posBaggingFraction: Positive Bagging fraction\n",
      " |  \n",
      " |  getPredictDisableShapeCheck(self)\n",
      " |      Returns:\n",
      " |          predictDisableShapeCheck: control whether or not LightGBM raises an error when you try to predict on data with a different number of features than the training data\n",
      " |  \n",
      " |  getPredictionCol(self)\n",
      " |      Returns:\n",
      " |          predictionCol: prediction column name\n",
      " |  \n",
      " |  getProbabilityCol(self)\n",
      " |      Returns:\n",
      " |          probabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities\n",
      " |  \n",
      " |  getRawPredictionCol(self)\n",
      " |      Returns:\n",
      " |          rawPredictionCol: raw prediction (a.k.a. confidence) column name\n",
      " |  \n",
      " |  getRepartitionByGroupingColumn(self)\n",
      " |      Returns:\n",
      " |          repartitionByGroupingColumn: Repartition training data according to grouping column, on by default.\n",
      " |  \n",
      " |  getSeed(self)\n",
      " |      Returns:\n",
      " |          seed: Main seed, used to generate other seeds\n",
      " |  \n",
      " |  getSkipDrop(self)\n",
      " |      Returns:\n",
      " |          skipDrop: Probability of skipping the dropout procedure during a boosting iteration\n",
      " |  \n",
      " |  getSlotNames(self)\n",
      " |      Returns:\n",
      " |          slotNames: List of slot names in the features column\n",
      " |  \n",
      " |  getThresholds(self)\n",
      " |      Returns:\n",
      " |          thresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0 excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold\n",
      " |  \n",
      " |  getTimeout(self)\n",
      " |      Returns:\n",
      " |          timeout: Timeout in seconds\n",
      " |  \n",
      " |  getTopK(self)\n",
      " |      Returns:\n",
      " |          topK: The top_k value used in Voting parallel, set this to larger value for more accurate result, but it will slow down the training speed. It should be greater than 0\n",
      " |  \n",
      " |  getTopRate(self)\n",
      " |      Returns:\n",
      " |          topRate: The retain ratio of large gradient data. Only used in goss.\n",
      " |  \n",
      " |  getUniformDrop(self)\n",
      " |      Returns:\n",
      " |          uniformDrop: Set this to true to use uniform drop in dart mode\n",
      " |  \n",
      " |  getUseBarrierExecutionMode(self)\n",
      " |      Returns:\n",
      " |          useBarrierExecutionMode: Barrier execution mode which uses a barrier stage, off by default.\n",
      " |  \n",
      " |  getUseMissing(self)\n",
      " |      Returns:\n",
      " |          useMissing: Set this to false to disable the special handle of missing value\n",
      " |  \n",
      " |  getUseSingleDatasetMode(self)\n",
      " |      Returns:\n",
      " |          useSingleDatasetMode: Use single dataset execution mode to create a single native dataset per executor (singleton) to reduce memory and communication overhead.\n",
      " |  \n",
      " |  getValidationIndicatorCol(self)\n",
      " |      Returns:\n",
      " |          validationIndicatorCol: Indicates whether the row is for training or validation\n",
      " |  \n",
      " |  getVerbosity(self)\n",
      " |      Returns:\n",
      " |          verbosity: Verbosity where lt 0 is Fatal, eq 0 is Error, eq 1 is Info, gt 1 is Debug\n",
      " |  \n",
      " |  getWeightCol(self)\n",
      " |      Returns:\n",
      " |          weightCol: The name of the weight column\n",
      " |  \n",
      " |  getXGBoostDartMode(self)\n",
      " |      Returns:\n",
      " |          xGBoostDartMode: Set this to true to use xgboost dart mode\n",
      " |  \n",
      " |  getZeroAsMissing(self)\n",
      " |      Returns:\n",
      " |          zeroAsMissing: Set to true to treat all zero as missing values (including the unshown values in LibSVM / sparse matrices). Set to false to use na for representing missing values\n",
      " |  \n",
      " |  setBaggingFraction(self, value)\n",
      " |      Args:\n",
      " |          baggingFraction: Bagging fraction\n",
      " |  \n",
      " |  setBaggingFreq(self, value)\n",
      " |      Args:\n",
      " |          baggingFreq: Bagging frequency\n",
      " |  \n",
      " |  setBaggingSeed(self, value)\n",
      " |      Args:\n",
      " |          baggingSeed: Bagging seed\n",
      " |  \n",
      " |  setBinSampleCount(self, value)\n",
      " |      Args:\n",
      " |          binSampleCount: Number of samples considered at computing histogram bins\n",
      " |  \n",
      " |  setBoostFromAverage(self, value)\n",
      " |      Args:\n",
      " |          boostFromAverage: Adjusts initial score to the mean of labels for faster convergence\n",
      " |  \n",
      " |  setBoostingType(self, value)\n",
      " |      Args:\n",
      " |          boostingType: Default gbdt = traditional Gradient Boosting Decision Tree. Options are: gbdt, gbrt, rf (Random Forest), random_forest, dart (Dropouts meet Multiple Additive Regression Trees), goss (Gradient-based One-Side Sampling).\n",
      " |  \n",
      " |  setCatSmooth(self, value)\n",
      " |      Args:\n",
      " |          catSmooth: this can reduce the effect of noises in categorical features, especially for categories with few data\n",
      " |  \n",
      " |  setCategoricalSlotIndexes(self, value)\n",
      " |      Args:\n",
      " |          categoricalSlotIndexes: List of categorical column indexes, the slot index in the features column\n",
      " |  \n",
      " |  setCategoricalSlotNames(self, value)\n",
      " |      Args:\n",
      " |          categoricalSlotNames: List of categorical column slot names, the slot name in the features column\n",
      " |  \n",
      " |  setCatl2(self, value)\n",
      " |      Args:\n",
      " |          catl2: L2 regularization in categorical split\n",
      " |  \n",
      " |  setChunkSize(self, value)\n",
      " |      Args:\n",
      " |          chunkSize: Advanced parameter to specify the chunk size for copying Java data to native.  If set too high, memory may be wasted, but if set too low, performance may be reduced during data copy.If dataset size is known beforehand, set to the number of rows in the dataset.\n",
      " |  \n",
      " |  setDataRandomSeed(self, value)\n",
      " |      Args:\n",
      " |          dataRandomSeed: Random seed for sampling data to construct histogram bins.\n",
      " |  \n",
      " |  setDefaultListenPort(self, value)\n",
      " |      Args:\n",
      " |          defaultListenPort: The default listen port on executors, used for testing\n",
      " |  \n",
      " |  setDeterministic(self, value)\n",
      " |      Args:\n",
      " |          deterministic: Used only with cpu devide type. Setting this to true should ensure stable results when using the same data and the same parameters.  Note: setting this to true may slow down training.  To avoid potential instability due to numerical issues, please set force_col_wise=true or force_row_wise=true when setting deterministic=true\n",
      " |  \n",
      " |  setDriverListenPort(self, value)\n",
      " |      Args:\n",
      " |          driverListenPort: The listen port on a driver. Default value is 0 (random)\n",
      " |  \n",
      " |  setDropRate(self, value)\n",
      " |      Args:\n",
      " |          dropRate: Dropout rate: a fraction of previous trees to drop during the dropout\n",
      " |  \n",
      " |  setDropSeed(self, value)\n",
      " |      Args:\n",
      " |          dropSeed: Random seed to choose dropping models. Only used in dart.\n",
      " |  \n",
      " |  setEarlyStoppingRound(self, value)\n",
      " |      Args:\n",
      " |          earlyStoppingRound: Early stopping round\n",
      " |  \n",
      " |  setExecutionMode(self, value)\n",
      " |      Args:\n",
      " |          executionMode: Specify how LightGBM is executed.  Values can be streaming, bulk. Default is bulk.\n",
      " |  \n",
      " |  setExtraSeed(self, value)\n",
      " |      Args:\n",
      " |          extraSeed: Random seed for selecting threshold when extra_trees is true\n",
      " |  \n",
      " |  setFeatureFraction(self, value)\n",
      " |      Args:\n",
      " |          featureFraction: Feature fraction\n",
      " |  \n",
      " |  setFeatureFractionByNode(self, value)\n",
      " |      Args:\n",
      " |          featureFractionByNode: Feature fraction by node\n",
      " |  \n",
      " |  setFeatureFractionSeed(self, value)\n",
      " |      Args:\n",
      " |          featureFractionSeed: Feature fraction seed\n",
      " |  \n",
      " |  setFeaturesCol(self, value)\n",
      " |      Args:\n",
      " |          featuresCol: features column name\n",
      " |  \n",
      " |  setFeaturesShapCol(self, value)\n",
      " |      Args:\n",
      " |          featuresShapCol: Output SHAP vector column name after prediction containing the feature contribution values\n",
      " |  \n",
      " |  setFobj(self, value)\n",
      " |      Args:\n",
      " |          fobj: Customized objective function. Should accept two parameters: preds, train_data, and return (grad, hess).\n",
      " |  \n",
      " |  setImprovementTolerance(self, value)\n",
      " |      Args:\n",
      " |          improvementTolerance: Tolerance to consider improvement in metric\n",
      " |  \n",
      " |  setInitScoreCol(self, value)\n",
      " |      Args:\n",
      " |          initScoreCol: The name of the initial score column, used for continued training\n",
      " |  \n",
      " |  setIsEnableSparse(self, value)\n",
      " |      Args:\n",
      " |          isEnableSparse: Used to enable/disable sparse optimization\n",
      " |  \n",
      " |  setIsProvideTrainingMetric(self, value)\n",
      " |      Args:\n",
      " |          isProvideTrainingMetric: Whether output metric result over training dataset.\n",
      " |  \n",
      " |  setIsUnbalance(self, value)\n",
      " |      Args:\n",
      " |          isUnbalance: Set to true if training data is unbalanced in binary classification scenario\n",
      " |  \n",
      " |  setLabelCol(self, value)\n",
      " |      Args:\n",
      " |          labelCol: label column name\n",
      " |  \n",
      " |  setLambdaL1(self, value)\n",
      " |      Args:\n",
      " |          lambdaL1: L1 regularization\n",
      " |  \n",
      " |  setLambdaL2(self, value)\n",
      " |      Args:\n",
      " |          lambdaL2: L2 regularization\n",
      " |  \n",
      " |  setLeafPredictionCol(self, value)\n",
      " |      Args:\n",
      " |          leafPredictionCol: Predicted leaf indices's column name\n",
      " |  \n",
      " |  setLearningRate(self, value)\n",
      " |      Args:\n",
      " |          learningRate: Learning rate or shrinkage rate\n",
      " |  \n",
      " |  setMatrixType(self, value)\n",
      " |      Args:\n",
      " |          matrixType: Advanced parameter to specify whether the native lightgbm matrix constructed should be sparse or dense.  Values can be auto, sparse or dense. Default value is auto, which samples first ten rows to determine type.\n",
      " |  \n",
      " |  setMaxBin(self, value)\n",
      " |      Args:\n",
      " |          maxBin: Max bin\n",
      " |  \n",
      " |  setMaxBinByFeature(self, value)\n",
      " |      Args:\n",
      " |          maxBinByFeature: Max number of bins for each feature\n",
      " |  \n",
      " |  setMaxCatThreshold(self, value)\n",
      " |      Args:\n",
      " |          maxCatThreshold: limit number of split points considered for categorical features\n",
      " |  \n",
      " |  setMaxCatToOnehot(self, value)\n",
      " |      Args:\n",
      " |          maxCatToOnehot: when number of categories of one feature smaller than or equal to this, one-vs-other split algorithm will be used\n",
      " |  \n",
      " |  setMaxDeltaStep(self, value)\n",
      " |      Args:\n",
      " |          maxDeltaStep: Used to limit the max output of tree leaves\n",
      " |  \n",
      " |  setMaxDepth(self, value)\n",
      " |      Args:\n",
      " |          maxDepth: Max depth\n",
      " |  \n",
      " |  setMaxDrop(self, value)\n",
      " |      Args:\n",
      " |          maxDrop: Max number of dropped trees during one boosting iteration\n",
      " |  \n",
      " |  setMetric(self, value)\n",
      " |      Args:\n",
      " |          metric: Metrics to be evaluated on the evaluation data.  Options are: empty string or not specified means that metric corresponding to specified objective will be used (this is possible only for pre-defined objective functions, otherwise no evaluation metric will be added). None (string, not a None value) means that no metric will be registered, aliases: na, null, custom. l1, absolute loss, aliases: mean_absolute_error, mae, regression_l1. l2, square loss, aliases: mean_squared_error, mse, regression_l2, regression. rmse, root square loss, aliases: root_mean_squared_error, l2_root. quantile, Quantile regression. mape, MAPE loss, aliases: mean_absolute_percentage_error. huber, Huber loss. fair, Fair loss. poisson, negative log-likelihood for Poisson regression. gamma, negative log-likelihood for Gamma regression. gamma_deviance, residual deviance for Gamma regression. tweedie, negative log-likelihood for Tweedie regression. ndcg, NDCG, aliases: lambdarank. map, MAP, aliases: mean_average_precision. auc, AUC. binary_logloss, log loss, aliases: binary. binary_error, for one sample: 0 for correct classification, 1 for error classification. multi_logloss, log loss for multi-class classification, aliases: multiclass, softmax, multiclassova, multiclass_ova, ova, ovr. multi_error, error rate for multi-class classification. cross_entropy, cross-entropy (with optional linear weights), aliases: xentropy. cross_entropy_lambda, intensity-weighted cross-entropy, aliases: xentlambda. kullback_leibler, Kullback-Leibler divergence, aliases: kldiv.\n",
      " |  \n",
      " |  setMicroBatchSize(self, value)\n",
      " |      Args:\n",
      " |          microBatchSize: Specify how many elements are sent in a streaming micro-batch.\n",
      " |  \n",
      " |  setMinDataInLeaf(self, value)\n",
      " |      Args:\n",
      " |          minDataInLeaf: Minimal number of data in one leaf. Can be used to deal with over-fitting.\n",
      " |  \n",
      " |  setMinDataPerBin(self, value)\n",
      " |      Args:\n",
      " |          minDataPerBin: Minimal number of data inside one bin\n",
      " |  \n",
      " |  setMinDataPerGroup(self, value)\n",
      " |      Args:\n",
      " |          minDataPerGroup: minimal number of data per categorical group\n",
      " |  \n",
      " |  setMinGainToSplit(self, value)\n",
      " |      Args:\n",
      " |          minGainToSplit: The minimal gain to perform split\n",
      " |  \n",
      " |  setMinSumHessianInLeaf(self, value)\n",
      " |      Args:\n",
      " |          minSumHessianInLeaf: Minimal sum hessian in one leaf\n",
      " |  \n",
      " |  setModelString(self, value)\n",
      " |      Args:\n",
      " |          modelString: LightGBM model to retrain\n",
      " |  \n",
      " |  setMonotoneConstraints(self, value)\n",
      " |      Args:\n",
      " |          monotoneConstraints: used for constraints of monotonic features. 1 means increasing, -1 means decreasing, 0 means non-constraint. Specify all features in order.\n",
      " |  \n",
      " |  setMonotoneConstraintsMethod(self, value)\n",
      " |      Args:\n",
      " |          monotoneConstraintsMethod: Monotone constraints method. basic, intermediate, or advanced.\n",
      " |  \n",
      " |  setMonotonePenalty(self, value)\n",
      " |      Args:\n",
      " |          monotonePenalty: A penalization parameter X forbids any monotone splits on the first X (rounded down) level(s) of the tree.\n",
      " |  \n",
      " |  setNegBaggingFraction(self, value)\n",
      " |      Args:\n",
      " |          negBaggingFraction: Negative Bagging fraction\n",
      " |  \n",
      " |  setNumBatches(self, value)\n",
      " |      Args:\n",
      " |          numBatches: If greater than 0, splits data into separate batches during training\n",
      " |  \n",
      " |  setNumIterations(self, value)\n",
      " |      Args:\n",
      " |          numIterations: Number of iterations, LightGBM constructs num_class * num_iterations trees\n",
      " |  \n",
      " |  setNumLeaves(self, value)\n",
      " |      Args:\n",
      " |          numLeaves: Number of leaves\n",
      " |  \n",
      " |  setNumTasks(self, value)\n",
      " |      Args:\n",
      " |          numTasks: Advanced parameter to specify the number of tasks.  SynapseML tries to guess this based on cluster configuration, but this parameter can be used to override.\n",
      " |  \n",
      " |  setNumThreads(self, value)\n",
      " |      Args:\n",
      " |          numThreads: Number of threads per executor for LightGBM. For the best speed, set this to the number of real CPU cores.\n",
      " |  \n",
      " |  setObjective(self, value)\n",
      " |      Args:\n",
      " |          objective: The Objective. For regression applications, this can be: regression_l2, regression_l1, huber, fair, poisson, quantile, mape, gamma or tweedie. For classification applications, this can be: binary, multiclass, or multiclassova.\n",
      " |  \n",
      " |  setObjectiveSeed(self, value)\n",
      " |      Args:\n",
      " |          objectiveSeed: Random seed for objectives, if random process is needed.  Currently used only for rank_xendcg objective.\n",
      " |  \n",
      " |  setOtherRate(self, value)\n",
      " |      Args:\n",
      " |          otherRate: The retain ratio of small gradient data. Only used in goss.\n",
      " |  \n",
      " |  setParallelism(self, value)\n",
      " |      Args:\n",
      " |          parallelism: Tree learner parallelism, can be set to data_parallel or voting_parallel\n",
      " |  \n",
      " |  setParams(self, baggingFraction=1.0, baggingFreq=0, baggingSeed=3, binSampleCount=200000, boostFromAverage=True, boostingType='gbdt', catSmooth=10.0, categoricalSlotIndexes=[], categoricalSlotNames=[], catl2=10.0, chunkSize=10000, dataRandomSeed=1, defaultListenPort=12400, deterministic=False, driverListenPort=0, dropRate=0.1, dropSeed=4, earlyStoppingRound=0, executionMode='bulk', extraSeed=6, featureFraction=1.0, featureFractionByNode=None, featureFractionSeed=2, featuresCol='features', featuresShapCol='', fobj=None, improvementTolerance=0.0, initScoreCol=None, isEnableSparse=True, isProvideTrainingMetric=False, isUnbalance=False, labelCol='label', lambdaL1=0.0, lambdaL2=0.0, leafPredictionCol='', learningRate=0.1, matrixType='auto', maxBin=255, maxBinByFeature=[], maxCatThreshold=32, maxCatToOnehot=4, maxDeltaStep=0.0, maxDepth=-1, maxDrop=50, metric='', microBatchSize=1, minDataInLeaf=20, minDataPerBin=3, minDataPerGroup=100, minGainToSplit=0.0, minSumHessianInLeaf=0.001, modelString='', monotoneConstraints=[], monotoneConstraintsMethod='basic', monotonePenalty=0.0, negBaggingFraction=1.0, numBatches=0, numIterations=100, numLeaves=31, numTasks=0, numThreads=0, objective='binary', objectiveSeed=5, otherRate=0.1, parallelism='data_parallel', passThroughArgs='', posBaggingFraction=1.0, predictDisableShapeCheck=False, predictionCol='prediction', probabilityCol='probability', rawPredictionCol='rawPrediction', repartitionByGroupingColumn=True, seed=None, skipDrop=0.5, slotNames=[], thresholds=None, timeout=1200.0, topK=20, topRate=0.2, uniformDrop=False, useBarrierExecutionMode=False, useMissing=True, useSingleDatasetMode=True, validationIndicatorCol=None, verbosity=-1, weightCol=None, xGBoostDartMode=False, zeroAsMissing=False)\n",
      " |      Set the (keyword only) parameters\n",
      " |  \n",
      " |  setPassThroughArgs(self, value)\n",
      " |      Args:\n",
      " |          passThroughArgs: Direct string to pass through to LightGBM library (appended with other explicitly set params). Will override any parameters given with explicit setters. Can include multiple parameters in one string.\n",
      " |  \n",
      " |  setPosBaggingFraction(self, value)\n",
      " |      Args:\n",
      " |          posBaggingFraction: Positive Bagging fraction\n",
      " |  \n",
      " |  setPredictDisableShapeCheck(self, value)\n",
      " |      Args:\n",
      " |          predictDisableShapeCheck: control whether or not LightGBM raises an error when you try to predict on data with a different number of features than the training data\n",
      " |  \n",
      " |  setPredictionCol(self, value)\n",
      " |      Args:\n",
      " |          predictionCol: prediction column name\n",
      " |  \n",
      " |  setProbabilityCol(self, value)\n",
      " |      Args:\n",
      " |          probabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities\n",
      " |  \n",
      " |  setRawPredictionCol(self, value)\n",
      " |      Args:\n",
      " |          rawPredictionCol: raw prediction (a.k.a. confidence) column name\n",
      " |  \n",
      " |  setRepartitionByGroupingColumn(self, value)\n",
      " |      Args:\n",
      " |          repartitionByGroupingColumn: Repartition training data according to grouping column, on by default.\n",
      " |  \n",
      " |  setSeed(self, value)\n",
      " |      Args:\n",
      " |          seed: Main seed, used to generate other seeds\n",
      " |  \n",
      " |  setSkipDrop(self, value)\n",
      " |      Args:\n",
      " |          skipDrop: Probability of skipping the dropout procedure during a boosting iteration\n",
      " |  \n",
      " |  setSlotNames(self, value)\n",
      " |      Args:\n",
      " |          slotNames: List of slot names in the features column\n",
      " |  \n",
      " |  setThresholds(self, value)\n",
      " |      Args:\n",
      " |          thresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0 excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold\n",
      " |  \n",
      " |  setTimeout(self, value)\n",
      " |      Args:\n",
      " |          timeout: Timeout in seconds\n",
      " |  \n",
      " |  setTopK(self, value)\n",
      " |      Args:\n",
      " |          topK: The top_k value used in Voting parallel, set this to larger value for more accurate result, but it will slow down the training speed. It should be greater than 0\n",
      " |  \n",
      " |  setTopRate(self, value)\n",
      " |      Args:\n",
      " |          topRate: The retain ratio of large gradient data. Only used in goss.\n",
      " |  \n",
      " |  setUniformDrop(self, value)\n",
      " |      Args:\n",
      " |          uniformDrop: Set this to true to use uniform drop in dart mode\n",
      " |  \n",
      " |  setUseBarrierExecutionMode(self, value)\n",
      " |      Args:\n",
      " |          useBarrierExecutionMode: Barrier execution mode which uses a barrier stage, off by default.\n",
      " |  \n",
      " |  setUseMissing(self, value)\n",
      " |      Args:\n",
      " |          useMissing: Set this to false to disable the special handle of missing value\n",
      " |  \n",
      " |  setUseSingleDatasetMode(self, value)\n",
      " |      Args:\n",
      " |          useSingleDatasetMode: Use single dataset execution mode to create a single native dataset per executor (singleton) to reduce memory and communication overhead.\n",
      " |  \n",
      " |  setValidationIndicatorCol(self, value)\n",
      " |      Args:\n",
      " |          validationIndicatorCol: Indicates whether the row is for training or validation\n",
      " |  \n",
      " |  setVerbosity(self, value)\n",
      " |      Args:\n",
      " |          verbosity: Verbosity where lt 0 is Fatal, eq 0 is Error, eq 1 is Info, gt 1 is Debug\n",
      " |  \n",
      " |  setWeightCol(self, value)\n",
      " |      Args:\n",
      " |          weightCol: The name of the weight column\n",
      " |  \n",
      " |  setXGBoostDartMode(self, value)\n",
      " |      Args:\n",
      " |          xGBoostDartMode: Set this to true to use xgboost dart mode\n",
      " |  \n",
      " |  setZeroAsMissing(self, value)\n",
      " |      Args:\n",
      " |          zeroAsMissing: Set to true to treat all zero as missing values (including the unshown values in LibSVM / sparse matrices). Set to false to use na for representing missing values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  read() from abc.ABCMeta\n",
      " |      Returns an MLReader instance for this class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  getJavaPackage()\n",
      " |      Returns package name String.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __parameters__ = ()\n",
      " |  \n",
      " |  baggingFraction = Param(parent='undefined', name='baggingFraction', do...\n",
      " |  \n",
      " |  baggingFreq = Param(parent='undefined', name='baggingFreq', doc='Baggi...\n",
      " |  \n",
      " |  baggingSeed = Param(parent='undefined', name='baggingSeed', doc='Baggi...\n",
      " |  \n",
      " |  binSampleCount = Param(parent='undefined', name='binSampleCount',... s...\n",
      " |  \n",
      " |  boostFromAverage = Param(parent='undefined', name='boostFromAverage......\n",
      " |  \n",
      " |  boostingType = Param(parent='undefined', name='boostingType', d...ees)...\n",
      " |  \n",
      " |  catSmooth = Param(parent='undefined', name='catSmooth', doc=...atures,...\n",
      " |  \n",
      " |  categoricalSlotIndexes = Param(parent='undefined', name='categoricalSl...\n",
      " |  \n",
      " |  categoricalSlotNames = Param(parent='undefined', name='categoricalSlot...\n",
      " |  \n",
      " |  catl2 = Param(parent='undefined', name='catl2', doc='L2 regularization...\n",
      " |  \n",
      " |  chunkSize = Param(parent='undefined', name='chunkSize', doc=...hand, s...\n",
      " |  \n",
      " |  dataRandomSeed = Param(parent='undefined', name='dataRandomSeed',... f...\n",
      " |  \n",
      " |  defaultListenPort = Param(parent='undefined', name='defaultListenPor.....\n",
      " |  \n",
      " |  deterministic = Param(parent='undefined', name='deterministic', ...e_r...\n",
      " |  \n",
      " |  driverListenPort = Param(parent='undefined', name='driverListenPort......\n",
      " |  \n",
      " |  dropRate = Param(parent='undefined', name='dropRate', doc='...on of pr...\n",
      " |  \n",
      " |  dropSeed = Param(parent='undefined', name='dropSeed', doc='...d to cho...\n",
      " |  \n",
      " |  earlyStoppingRound = Param(parent='undefined', name='earlyStoppingRoun...\n",
      " |  \n",
      " |  executionMode = Param(parent='undefined', name='executionMode', ...Val...\n",
      " |  \n",
      " |  extraSeed = Param(parent='undefined', name='extraSeed', doc=...or sele...\n",
      " |  \n",
      " |  featureFraction = Param(parent='undefined', name='featureFraction', do...\n",
      " |  \n",
      " |  featureFractionByNode = Param(parent='undefined', name='featureFractio...\n",
      " |  \n",
      " |  featureFractionSeed = Param(parent='undefined', name='featureFractionS...\n",
      " |  \n",
      " |  featuresCol = Param(parent='undefined', name='featuresCol', doc='featu...\n",
      " |  \n",
      " |  featuresShapCol = Param(parent='undefined', name='featuresShapCol'...t...\n",
      " |  \n",
      " |  fobj = Param(parent='undefined', name='fobj', doc='Cust...rs: preds, t...\n",
      " |  \n",
      " |  improvementTolerance = Param(parent='undefined', name='improvementTole...\n",
      " |  \n",
      " |  initScoreCol = Param(parent='undefined', name='initScoreCol', d...itia...\n",
      " |  \n",
      " |  isEnableSparse = Param(parent='undefined', name='isEnableSparse', doc=...\n",
      " |  \n",
      " |  isProvideTrainingMetric = Param(parent='undefined', name='isProvideTra...\n",
      " |  \n",
      " |  isUnbalance = Param(parent='undefined', name='isUnbalance', do...is un...\n",
      " |  \n",
      " |  labelCol = Param(parent='undefined', name='labelCol', doc='label colum...\n",
      " |  \n",
      " |  lambdaL1 = Param(parent='undefined', name='lambdaL1', doc='L1 regulari...\n",
      " |  \n",
      " |  lambdaL2 = Param(parent='undefined', name='lambdaL2', doc='L2 regulari...\n",
      " |  \n",
      " |  leafPredictionCol = Param(parent='undefined', name='leafPredictionCol'...\n",
      " |  \n",
      " |  learningRate = Param(parent='undefined', name='learningRate', doc='Lea...\n",
      " |  \n",
      " |  matrixType = Param(parent='undefined', name='matrixType', doc...which ...\n",
      " |  \n",
      " |  maxBin = Param(parent='undefined', name='maxBin', doc='Max bin')\n",
      " |  \n",
      " |  maxBinByFeature = Param(parent='undefined', name='maxBinByFeature', do...\n",
      " |  \n",
      " |  maxCatThreshold = Param(parent='undefined', name='maxCatThreshold'...p...\n",
      " |  \n",
      " |  maxCatToOnehot = Param(parent='undefined', name='maxCatToOnehot',...th...\n",
      " |  \n",
      " |  maxDeltaStep = Param(parent='undefined', name='maxDeltaStep', doc='Use...\n",
      " |  \n",
      " |  maxDepth = Param(parent='undefined', name='maxDepth', doc='Max depth')\n",
      " |  \n",
      " |  maxDrop = Param(parent='undefined', name='maxDrop', doc='M... of dropp...\n",
      " |  \n",
      " |  metric = Param(parent='undefined', name='metric', doc='Me..., Kullback...\n",
      " |  \n",
      " |  microBatchSize = Param(parent='undefined', name='microBatchSize',...y ...\n",
      " |  \n",
      " |  minDataInLeaf = Param(parent='undefined', name='minDataInLeaf', ...ne ...\n",
      " |  \n",
      " |  minDataPerBin = Param(parent='undefined', name='minDataPerBin', doc='M...\n",
      " |  \n",
      " |  minDataPerGroup = Param(parent='undefined', name='minDataPerGroup'...c...\n",
      " |  \n",
      " |  minGainToSplit = Param(parent='undefined', name='minGainToSplit', doc=...\n",
      " |  \n",
      " |  minSumHessianInLeaf = Param(parent='undefined', name='minSumHessianInL...\n",
      " |  \n",
      " |  modelString = Param(parent='undefined', name='modelString', doc='Light...\n",
      " |  \n",
      " |  monotoneConstraints = Param(parent='undefined', name='monotoneConstrai...\n",
      " |  \n",
      " |  monotoneConstraintsMethod = Param(parent='undefined', name='monotoneCo...\n",
      " |  \n",
      " |  monotonePenalty = Param(parent='undefined', name='monotonePenalty'...h...\n",
      " |  \n",
      " |  negBaggingFraction = Param(parent='undefined', name='negBaggingFractio...\n",
      " |  \n",
      " |  numBatches = Param(parent='undefined', name='numBatches', doc...lits d...\n",
      " |  \n",
      " |  numIterations = Param(parent='undefined', name='numIterations', ...GBM...\n",
      " |  \n",
      " |  numLeaves = Param(parent='undefined', name='numLeaves', doc='Number of...\n",
      " |  \n",
      " |  numTasks = Param(parent='undefined', name='numTasks', doc='...on, but ...\n",
      " |  \n",
      " |  numThreads = Param(parent='undefined', name='numThreads', doc...peed, ...\n",
      " |  \n",
      " |  objective = Param(parent='undefined', name='objective', doc=... can be...\n",
      " |  \n",
      " |  objectiveSeed = Param(parent='undefined', name='objectiveSeed', ... Cu...\n",
      " |  \n",
      " |  otherRate = Param(parent='undefined', name='otherRate', doc=...atio of...\n",
      " |  \n",
      " |  parallelism = Param(parent='undefined', name='parallelism', do... can ...\n",
      " |  \n",
      " |  passThroughArgs = Param(parent='undefined', name='passThroughArgs'... ...\n",
      " |  \n",
      " |  posBaggingFraction = Param(parent='undefined', name='posBaggingFractio...\n",
      " |  \n",
      " |  predictDisableShapeCheck = Param(parent='undefined', name='predictDisa...\n",
      " |  \n",
      " |  predictionCol = Param(parent='undefined', name='predictionCol', doc='p...\n",
      " |  \n",
      " |  probabilityCol = Param(parent='undefined', name='probabilityCol',...ea...\n",
      " |  \n",
      " |  rawPredictionCol = Param(parent='undefined', name='rawPredictionCol......\n",
      " |  \n",
      " |  repartitionByGroupingColumn = Param(parent='undefined', name='repartit...\n",
      " |  \n",
      " |  seed = Param(parent='undefined', name='seed', doc='Main seed, used to ...\n",
      " |  \n",
      " |  skipDrop = Param(parent='undefined', name='skipDrop', doc='...e dropou...\n",
      " |  \n",
      " |  slotNames = Param(parent='undefined', name='slotNames', doc='List of s...\n",
      " |  \n",
      " |  thresholds = Param(parent='undefined', name='thresholds', doc...ty of ...\n",
      " |  \n",
      " |  timeout = Param(parent='undefined', name='timeout', doc='Timeout in se...\n",
      " |  \n",
      " |  topK = Param(parent='undefined', name='topK', doc='The ...the training...\n",
      " |  \n",
      " |  topRate = Param(parent='undefined', name='topRate', doc='T...atio of l...\n",
      " |  \n",
      " |  uniformDrop = Param(parent='undefined', name='uniformDrop', do...t thi...\n",
      " |  \n",
      " |  useBarrierExecutionMode = Param(parent='undefined', name='useBarrierEx...\n",
      " |  \n",
      " |  useMissing = Param(parent='undefined', name='useMissing', doc... to di...\n",
      " |  \n",
      " |  useSingleDatasetMode = Param(parent='undefined', name='useSingleDatase...\n",
      " |  \n",
      " |  validationIndicatorCol = Param(parent='undefined', name='validationInd...\n",
      " |  \n",
      " |  verbosity = Param(parent='undefined', name='verbosity', doc=...tal, eq...\n",
      " |  \n",
      " |  weightCol = Param(parent='undefined', name='weightCol', doc='The name ...\n",
      " |  \n",
      " |  xGBoostDartMode = Param(parent='undefined', name='xGBoostDartMode', do...\n",
      " |  \n",
      " |  zeroAsMissing = Param(parent='undefined', name='zeroAsMissing', ...fal...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pyspark.ml.util.JavaMLReadable:\n",
      " |  \n",
      " |  __orig_bases__ = (pyspark.ml.util.MLReadable[~RL],)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pyspark.ml.util.MLReadable:\n",
      " |  \n",
      " |  load(path: str) -> ~RL from abc.ABCMeta\n",
      " |      Reads an ML instance from the input path, a shortcut of `read().load(path)`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pyspark.ml.util.MLReadable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pyspark.ml.util.JavaMLWritable:\n",
      " |  \n",
      " |  write(self) -> pyspark.ml.util.JavaMLWriter\n",
      " |      Returns an MLWriter instance for this ML instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pyspark.ml.util.MLWritable:\n",
      " |  \n",
      " |  save(self, path: str) -> None\n",
      " |      Save this ML instance to the given path, a shortcut of 'write().save(path)'.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pyspark.ml.wrapper.JavaParams:\n",
      " |  \n",
      " |  clear(self, param: pyspark.ml.param.Param) -> None\n",
      " |      Clears a param from the param map if it has been explicitly set.\n",
      " |  \n",
      " |  copy(self: 'JP', extra: Optional[ForwardRef('ParamMap')] = None) -> 'JP'\n",
      " |      Creates a copy of this instance with the same uid and some\n",
      " |      extra params. This implementation first calls Params.copy and\n",
      " |      then make a copy of the companion Java pipeline component with\n",
      " |      extra params. So both the Python wrapper and the Java pipeline\n",
      " |      component get copied.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      extra : dict, optional\n",
      " |          Extra parameters to copy to the new instance\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :py:class:`JavaParams`\n",
      " |          Copy of this instance\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pyspark.ml.wrapper.JavaWrapper:\n",
      " |  \n",
      " |  __del__(self) -> None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pyspark.ml.base.Estimator:\n",
      " |  \n",
      " |  fit(self, dataset: pyspark.sql.dataframe.DataFrame, params: Union[ForwardRef('ParamMap'), List[ForwardRef('ParamMap')], Tuple[ForwardRef('ParamMap')], NoneType] = None) -> Union[~M, List[~M]]\n",
      " |      Fits a model to the input dataset with optional parameters.\n",
      " |      \n",
      " |      .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset : :py:class:`pyspark.sql.DataFrame`\n",
      " |          input dataset.\n",
      " |      params : dict or list or tuple, optional\n",
      " |          an optional param map that overrides embedded params. If a list/tuple of\n",
      " |          param maps is given, this calls fit on each param map and returns a list of\n",
      " |          models.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :py:class:`Transformer` or a list of :py:class:`Transformer`\n",
      " |          fitted model(s)\n",
      " |  \n",
      " |  fitMultiple(self, dataset: pyspark.sql.dataframe.DataFrame, paramMaps: Sequence[ForwardRef('ParamMap')]) -> Iterator[Tuple[int, ~M]]\n",
      " |      Fits a model to the input dataset for each param map in `paramMaps`.\n",
      " |      \n",
      " |      .. versionadded:: 2.3.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset : :py:class:`pyspark.sql.DataFrame`\n",
      " |          input dataset.\n",
      " |      paramMaps : :py:class:`collections.abc.Sequence`\n",
      " |          A Sequence of param maps.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :py:class:`_FitMultipleIterator`\n",
      " |          A thread safe iterable which contains one model for each param map. Each\n",
      " |          call to `next(modelIterator)` will return `(index, model)` where model was fit\n",
      " |          using `paramMaps[index]`. `index` values may not be sequential.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pyspark.ml.param.Params:\n",
      " |  \n",
      " |  explainParam(self, param: Union[str, pyspark.ml.param.Param]) -> str\n",
      " |      Explains a single param and returns its name, doc, and optional\n",
      " |      default value and user-supplied value in a string.\n",
      " |  \n",
      " |  explainParams(self) -> str\n",
      " |      Returns the documentation of all params with their optionally\n",
      " |      default values and user-supplied values.\n",
      " |  \n",
      " |  extractParamMap(self, extra: Optional[ForwardRef('ParamMap')] = None) -> 'ParamMap'\n",
      " |      Extracts the embedded default param values and user-supplied\n",
      " |      values, and then merges them with extra values from input into\n",
      " |      a flat param map, where the latter value is used if there exist\n",
      " |      conflicts, i.e., with ordering: default param values <\n",
      " |      user-supplied values < extra.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      extra : dict, optional\n",
      " |          extra param values\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict\n",
      " |          merged param map\n",
      " |  \n",
      " |  getOrDefault(self, param: Union[str, pyspark.ml.param.Param[~T]]) -> Union[Any, ~T]\n",
      " |      Gets the value of a param in the user-supplied param map or its\n",
      " |      default value. Raises an error if neither is set.\n",
      " |  \n",
      " |  getParam(self, paramName: str) -> pyspark.ml.param.Param\n",
      " |      Gets a param by its name.\n",
      " |  \n",
      " |  hasDefault(self, param: Union[str, pyspark.ml.param.Param[Any]]) -> bool\n",
      " |      Checks whether a param has a default value.\n",
      " |  \n",
      " |  hasParam(self, paramName: str) -> bool\n",
      " |      Tests whether this instance contains a param with a given\n",
      " |      (string) name.\n",
      " |  \n",
      " |  isDefined(self, param: Union[str, pyspark.ml.param.Param[Any]]) -> bool\n",
      " |      Checks whether a param is explicitly set by user or has\n",
      " |      a default value.\n",
      " |  \n",
      " |  isSet(self, param: Union[str, pyspark.ml.param.Param[Any]]) -> bool\n",
      " |      Checks whether a param is explicitly set by user.\n",
      " |  \n",
      " |  set(self, param: pyspark.ml.param.Param, value: Any) -> None\n",
      " |      Sets a parameter in the embedded param map.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pyspark.ml.param.Params:\n",
      " |  \n",
      " |  params\n",
      " |      Returns all params ordered by name. The default implementation\n",
      " |      uses :py:func:`dir` to get all attributes of type\n",
      " |      :py:class:`Param`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pyspark.ml.util.Identifiable:\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from abc.ABCMeta\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lgbmClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b951b892",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
